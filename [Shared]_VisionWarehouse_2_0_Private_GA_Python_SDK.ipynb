{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gfilicetti/vision-warehouse-examples/blob/main/%5BShared%5D_VisionWarehouse_2_0_Private_GA_Python_SDK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvTx8xICs6pK"
      },
      "source": [
        "# Get Started (ðŸ›‘ Attention Required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK-qt79Bs-L-"
      },
      "source": [
        "Before starting,\n",
        "* Make a copy of the colab before you run it.\n",
        "* Get added to the allowlist by sending an email to warehouse-v2-trusted-testers-mailing-external+managers@google.com.\n",
        "  * Mention the email account to get the access to colab and SDK.\n",
        "  * Ask for the allowlist for the project. Mention the project ID in the email.\n",
        "* Model garden models (speech, OCR) requires the quota of the underlying prediction services to be sufficient, e.g. to run **one** video api model for **100** concurrent AnalyzeAsset, suggest to request QPM 125 and backend seconds to be 6000. You can request corresponding quota based on your estimated concurrency. Video API [default quota](https://docs.cloud.google.com/video-intelligence/quotas) request QPM is 60 and backend seconds is 180, which means can allow 3 videos processing at the same time. The default quota is sufficient for the colab demo purpose.\n",
        "\n",
        "* To avoid charges after test, you need to undeploy the index (see the clean up [undeply index section](https://colab.research.google.com/drive/1S-fKU8gTM6jPKd_-Dt9U4ed3qkUB_hAt?resourcekey=0-ri3myj9ID9aBDr0ON7xuUw#scrollTo=6neZMt-YSJh7)).\n",
        "* The colab is for demo the Warehouse CUJ purpose, and is not for processing large number of files because the colab session may disconnected. So the colab checks the number of input files is less than **20**. Though Warehouse service supports videos up to 15h, due to limitations of colab session and LRO polling timeout (currently set as 2h in colab), it is suggested to test with shorter video lengths in the colab (**<1h**). Please keep the colab session connected during the run.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Main Demo\n",
        "\n",
        "Demo how to ingest a bunch of video files into Warehouse and Search."
      ],
      "metadata": {
        "id": "J8MK2BPsr2uu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "_mHR1f_Wotwr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOobtzpW3TJB"
      },
      "source": [
        "At the highest level, there is a simple three-stage process for getting your content into our system and making it searchable.\n",
        "\n",
        "1.  Provision Corpus: A one-time setup step to create a container for your data and prepare the backend services.\n",
        "2.  Ingest Videos: The process of adding your video assets, applying machine learning, and attaching your custom metadata.\n",
        "3.  Search: The final step where your application can query the system to find relevant videos or video segments.\n",
        "\n",
        "\n",
        "--------------------------------------\n",
        "\n",
        "| Step | Approximately time |\n",
        "| :--- | :--- |\n",
        "| [Step 1: Provision Corpus](https://colab.research.google.com/drive/1S-fKU8gTM6jPKd_-Dt9U4ed3qkUB_hAt?resourcekey=0-ri3myj9ID9aBDr0ON7xuUw#scrollTo=6gIcJvfN2XAz) | Avg: 2 hour, One Time setup |\n",
        "| [Step 2: Ingest Videos](https://colab.research.google.com/drive/1S-fKU8gTM6jPKd_-Dt9U4ed3qkUB_hAt?resourcekey=0-ri3myj9ID9aBDr0ON7xuUw#scrollTo=5ghMbrQhuEox) | Depends on the video duration, if 1 hour video, it takes 1 hour to ingest. |\n",
        "| [Step 3: Search](https://colab.research.google.com/drive/1S-fKU8gTM6jPKd_-Dt9U4ed3qkUB_hAt?resourcekey=0-ri3myj9ID9aBDr0ON7xuUw#scrollTo=M_ZHmBe53sNV) |  Instance |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pricing"
      ],
      "metadata": {
        "id": "ZUqdoLXmme3D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Model garden models (currently supported speech transcription and text detection) will charge the cost to the underlying prediction services, e.g. speech & OCR will charge to Video API.\n",
        "* Warehourse pricing see https://cloud.google.com/vision-ai/pricing. Please undeploy the index endpoint after testing to avoid further charges."
      ],
      "metadata": {
        "id": "7djykuwfmhUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limitations"
      ],
      "metadata": {
        "id": "pXpK1-AWpkWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "* Don't support update existing EMBEDDING_SEARCH corpus to DEFAULT_SEARCH.\n",
        "\n",
        "* It is expected to observe similar search results for EMBEDDING_SEARCH vs DEFAULT_SEARCH if you are using non-English search query. Please use English search query for testing the search quality difference between the two. Stay tuned for more languages support in the future.\n",
        "\n",
        "* For speech transcription, currently only support specifying one audio track. Language must be specified. Only en-US is supported. In this colab, it will use audio track 0 for speech transcription if the video has audio tracks.\n",
        "\n",
        "* It is not allowed to update the config used for the same model, e.g. updating the audio tracks used for the speech transcription model. To do that, you can\n",
        "\n",
        "  * Option 1: Create new asset.\n",
        "\n",
        "  * Option 2: Update the existing asset removing the model_garden_model_context entry of the model, run AnalyzeAsset which will clean up the annotations of the removed model, and then update the asset with the correct model_garden_model_context and run AnalyzeAsset again."
      ],
      "metadata": {
        "id": "2NMmj0xSmWhj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wocEV-3ktEOM"
      },
      "source": [
        "## Set Up Eviornment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authentication"
      ],
      "metadata": {
        "id": "C5D777umqVas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "n7V21ShWqWPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download SDK"
      ],
      "metadata": {
        "id": "Vx_g1lPsqGv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp gs://visionai-warehouse-v2-preview/visionai-v1-py.tar.gz .\n",
        "!tar -xf visionai-v1-py.tar.gz\n",
        "!ls\n",
        "!pip3 install visionai-v1-py/"
      ],
      "metadata": {
        "id": "fIxOTS96CoWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up Variables (ðŸ›‘ Actions Required)"
      ],
      "metadata": {
        "id": "8qs0W7UTESdx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i58SXdzu-mnm"
      },
      "outputs": [],
      "source": [
        "#@title ðŸ›‘ Required: Set Your Project Id\n",
        "PROJECT_ID=\"\" # @param {type: \"string\"}\n",
        "\n",
        "PROJECT_NUMBER_STR=!gcloud projects describe {PROJECT_ID} --format=\"value(projectNumber)\"\n",
        "PROJECT_NUMBER=int(PROJECT_NUMBER_STR[0])\n",
        "LOCATION_ID = 'us-central1' #@param [\"us-central1\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Optional: Other variables.\n",
        "# Please set it at least 2 times of the video length.\n",
        "TIMEOUT_SECS=7200\n",
        "# Warehouse provides the optional to turn on the sports enhancement which mainly applies to American football.\n",
        "IS_AMERICAN_FOOTBALL=False"
      ],
      "metadata": {
        "id": "lwlfRvfYdTM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ›‘ Required: Define Your Input Videos"
      ],
      "metadata": {
        "id": "80003wTG7Exq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run this cell to render the input widget.\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "select_file_input_method = widgets.RadioButtons(\n",
        "    options=['GCS Bucket (e.g., gs://my-data-bucket)', 'List of GCS Files (one path per line)'],\n",
        "    value='GCS Bucket (e.g., gs://my-data-bucket)',\n",
        "    description='Input Type:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='auto'),\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "bucket_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='gs://your-bucket-name',\n",
        "    description='Bucket Path:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='600px')\n",
        ")\n",
        "file_list_input = widgets.Textarea(\n",
        "    value='gs://cloud-samples-data/video/JaneGoodall.mp4\\ngs://cloud-samples-data/video/pizza.mp4\\ngs://cloud-samples-data/video/animals.mp4',\n",
        "    placeholder='gs://bucket/file1.mp4\\ngs://bucket/file2.mov\\ngs://bucket/folder/file3.ts',\n",
        "    description='File List:',\n",
        "    disabled=False,\n",
        "    rows=5,\n",
        "    layout=widgets.Layout(width='600px')\n",
        ")\n",
        "\n",
        "input_container = widgets.VBox([bucket_input])\n",
        "message_output = widgets.Output()\n",
        "\n",
        "def on_file_input_radio_change(change):\n",
        "    \"\"\"Dynamically updates the input field and the instruction message.\"\"\"\n",
        "\n",
        "    with message_output:\n",
        "        message_output.clear_output(wait=True)\n",
        "\n",
        "        if 'GCS Bucket' in change['new']:\n",
        "            input_container.children = [bucket_input]\n",
        "            print(\"ðŸ’¡ Please enter a single GCS bucket path. All files in this bucket will be processed.\")\n",
        "        elif 'List of GCS Files' in change['new']:\n",
        "            input_container.children = [file_list_input]\n",
        "            print(\"ðŸ’¡ Please enter a list of complete GCS file paths, one per line.\")\n",
        "\n",
        "select_file_input_method.observe(on_file_input_radio_change, names='value')\n",
        "\n",
        "display(select_file_input_method)\n",
        "display(message_output)\n",
        "display(input_container)\n",
        "\n",
        "on_file_input_radio_change({'new': select_file_input_method.value, 'old': None})"
      ],
      "metadata": {
        "id": "oVlwBREOxi2c",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ›‘ Required: Provision New Or Use Exising Corpus/Index/IndexEndpoint"
      ],
      "metadata": {
        "id": "ufCLAj9p7fwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run this cell to render the input widget.\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "choice_widget = widgets.RadioButtons(\n",
        "    options=['Create New Corpus', 'Use Existing IDs'],\n",
        "    value='Use Existing IDs',\n",
        "    description='Setup Mode:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "corpus_input = widgets.Text(\n",
        "    description='Corpus ID:',\n",
        "    placeholder='Enter existing corpus ID...',\n",
        "    layout=widgets.Layout(width='auto')\n",
        ")\n",
        "\n",
        "index_input = widgets.Text(\n",
        "    description='Index ID:',\n",
        "    placeholder='Enter existing index ID...',\n",
        "    layout=widgets.Layout(width='auto')\n",
        ")\n",
        "\n",
        "endpoint_input = widgets.Text(\n",
        "    description='Endpoint ID:',\n",
        "    placeholder='Enter existing endpoint ID...',\n",
        "    layout=widgets.Layout(width='auto')\n",
        ")\n",
        "\n",
        "id_input_box = widgets.VBox([corpus_input, index_input, endpoint_input])\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_provision_choice_change(change):\n",
        "    \"\"\"Callback function to run when the user changes the radio button.\"\"\"\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "\n",
        "        if change['new'] == 'Use Existing IDs':\n",
        "            print(\"âš ï¸ Please enter the three required IDs below.\")\n",
        "            display(id_input_box)\n",
        "        else:\n",
        "            print(\"âœ… Ready to provision a new warehouse corpus from scratch.\")\n",
        "\n",
        "display(choice_widget)\n",
        "\n",
        "choice_widget.observe(on_provision_choice_change, names='value')\n",
        "\n",
        "on_provision_choice_change({'new': choice_widget.value})\n",
        "\n",
        "display(output)\n",
        "\n"
      ],
      "metadata": {
        "id": "7zrzS1bombPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ›‘ Required: Whether Clean Up After Tests\n",
        "\n",
        "If the index is deployed, it will continue charging the index serving cost.\n",
        "\n",
        "**ATTENTION**: After the index is undeployed, you won't be able to search the corpus. So it is suggested:\n",
        "\n",
        "* Step 1: Don't check any variables here and run the \"Build the Warehouse\" section.\n",
        "\n",
        "* Step 2: Try out the searches with your own search queries.\n",
        "\n",
        "* Step 3: Then to stop billing without deleting assets/corpus, you can check the undeploy_index option.\n",
        "   \n",
        "   * 3.1 : If the colab session is not disconnected, you can just run the \"Step 4: Clean up > Undeploy Index \" section.\n",
        "   \n",
        "   * 3.2: If the colab session has been expired, first set the corpus id, index id, index endpoint id in the \"Required:Provision New or Use Existing Corpus/Index/IndexEndpoint\" and then run the \"Build the Warehouse > Preparation\" section and then run the \"Step 4: Clean up > Undeploy Index\" section."
      ],
      "metadata": {
        "id": "uitFuLP08Wby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run this cell to render the input widget.\n",
        "delete_assets_widget = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='DELETE_ASSETS',\n",
        "    disabled=False,\n",
        "    indent=False\n",
        ")\n",
        "\n",
        "undeploy_index_widget = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='UNDEPLOY_INDEX',\n",
        "    disabled=False,\n",
        "    indent=False\n",
        ")\n",
        "\n",
        "delete_index_widget = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='DELETE_INDEX',\n",
        "    disabled=False,\n",
        "    indent=False\n",
        ")\n",
        "\n",
        "delete_index_endpoint_widget = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='DELETE_INDEX_ENDPOINT',\n",
        "    disabled=False,\n",
        "    indent=False\n",
        ")\n",
        "\n",
        "delete_corpus_widget = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='DELETE_CORPUS',\n",
        "    disabled=False,\n",
        "    indent=False\n",
        ")\n",
        "\n",
        "# Display the widgets\n",
        "display(\n",
        "    delete_assets_widget,\n",
        "    undeploy_index_widget,\n",
        "    delete_index_widget,\n",
        "    delete_index_endpoint_widget,\n",
        "    delete_corpus_widget\n",
        ")"
      ],
      "metadata": {
        "id": "VxKh1TLaMrIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ðŸ›‘ After setting the inputs above, now you can run the \"Build the Warehouse\" section all together (by hovering the mouse at the section title in the left hand \"Table of contents\" and click the â–¶ button). Please **DON'T** rerun the above cells which will empty your inputs."
      ],
      "metadata": {
        "id": "wkEGuwK11zCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Warehouse"
      ],
      "metadata": {
        "id": "Q-AYhYmRtKlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation"
      ],
      "metadata": {
        "id": "emBKYnTr2RJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ],
      "metadata": {
        "id": "BOXdzKHsyK-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import TimeoutError\n",
        "from google.api_core import exceptions as google_exceptions\n",
        "from google.cloud import visionai_v1\n",
        "from google.longrunning import operations_pb2\n",
        "from google.protobuf import duration_pb2\n",
        "from google.protobuf import struct_pb2\n",
        "from IPython.display import display, Markdown, HTML, Image\n",
        "from typing import Optional, List, Any, Dict\n",
        "import concurrent.futures\n",
        "import dataclasses\n",
        "import datetime\n",
        "import grpc\n",
        "import logging\n",
        "import os\n",
        "import pandas as pd\n",
        "import shlex\n",
        "import subprocess\n",
        "import sys\n",
        "import time"
      ],
      "metadata": {
        "id": "HRUYcchX1qmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creates a Warehouse Client"
      ],
      "metadata": {
        "id": "WL_aTssbVQuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.INFO,\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "                    force=True)\n",
        "\n",
        "# Initialize the client ONCE\n",
        "try:\n",
        "    warehouse_client = visionai_v1.WarehouseClient(\n",
        "      client_options={\"api_endpoint\": \"warehouse-visionai.googleapis.com\"},\n",
        "    )\n",
        "\n",
        "    logging.info(\"WarehouseClient initialized successfully.\")\n",
        "except Exception as e:\n",
        "    logging.critical(f\"Failed to initialize WarehouseClient: {e}\")\n",
        "\n",
        "\n",
        "# --- Type Hinting ---\n",
        "try:\n",
        "    from google.cloud.visionai_v1 import (\n",
        "        WarehouseClient,\n",
        "        Asset,\n",
        "        DataSchema,\n",
        "        Annotation,\n",
        "        CreateAssetRequest,\n",
        "        CreateDataSchemaRequest,\n",
        "        CreateAnnotationRequest,\n",
        "        UploadAssetRequest,\n",
        "        UploadAssetResponse,\n",
        "        AnalyzeAssetRequest,\n",
        "        AnalyzeAssetResponse,\n",
        "        IndexAssetRequest,\n",
        "        IndexAssetResponse,\n",
        "    )\n",
        "except ImportError:\n",
        "    logging.warning(\"WarehouseClient or other types not imported, using 'Any'.\")\n",
        "    WarehouseClient = Any\n",
        "    Asset = Any\n",
        "    DataSchema = Any\n",
        "    Annotation = Any\n",
        "    CreateAssetRequest = Any\n",
        "    CreateDataSchemaRequest = Any\n",
        "    CreateAnnotationRequest = Any\n",
        "    UploadAssetRequest = Any\n",
        "    UploadAssetResponse = Any\n",
        "    AnalyzeAssetRequest = Any\n",
        "    AnalyzeAssetResponse = Any\n",
        "    IndexAssetRequest = Any\n",
        "    IndexAssetResponse = Any"
      ],
      "metadata": {
        "id": "cX4PNVDZVcru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Construct Resource Names if Using Existing Corpus/Index/IndexEndpoint\n",
        "\n"
      ],
      "metadata": {
        "id": "fh0RdyflYFx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "need_provision = (choice_widget.value == 'Create New Corpus')\n",
        "\n",
        "if not need_provision:\n",
        "    # IDs come from the widget input fields\n",
        "    corpus_id = corpus_input.value\n",
        "    index_id = index_input.value\n",
        "    index_endpoint_id = endpoint_input.value\n",
        "\n",
        "    parent_name=f\"projects/{PROJECT_NUMBER}/locations/{LOCATION_ID}\"\n",
        "    corpus_name = f\"{parent_name}/corpora/{corpus_id}\"\n",
        "    index_name = f\"{parent_name}/corpora/{corpus_id}/indexes/{index_id}\"\n",
        "    index_endpoint_name = f\"{parent_name}/indexEndpoints/{index_endpoint_id}\"\n",
        "    logging.info(\"âœ… No Provision is needed as existing ids are used.\")\n",
        "    logging.info (f\"Corpus         : {corpus_name}\")\n",
        "    logging.info (f\"Index          : {index_name}\")\n",
        "    logging.info (f\"Index Endpoint : {index_endpoint_name}\")"
      ],
      "metadata": {
        "id": "67N6vLyQYQs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collect Files from User Input\n"
      ],
      "metadata": {
        "id": "_u3VBgth5zGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_names = []\n",
        "\n",
        "# Get the selected option and the raw input values\n",
        "selected_option = select_file_input_method.value\n",
        "bucket_path = bucket_input.value.strip()\n",
        "file_list_raw = file_list_input.value.strip()\n",
        "\n",
        "print(\"--- Starting File List Collection ---\")\n",
        "\n",
        "# --- Logic for GCS Bucket ---\n",
        "if 'GCS Bucket' in selected_option:\n",
        "    GCS_SOURCE = bucket_path\n",
        "\n",
        "    if not GCS_SOURCE or not GCS_SOURCE.startswith('gs://'):\n",
        "        print(\"ðŸ›‘ ERROR: Please enter a valid GCS bucket path starting with 'gs://'.\")\n",
        "    else:\n",
        "        print(f\"ðŸ“ Listing files from bucket: {GCS_SOURCE}\")\n",
        "\n",
        "        # Use gsutil ls to list all files in the bucket.\n",
        "        # The output is captured and split into individual lines.\n",
        "        try:\n",
        "            gsutil_command = f'gsutil ls {GCS_SOURCE}'\n",
        "            result = subprocess.run(\n",
        "                shlex.split(gsutil_command),\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                check=True\n",
        "            )\n",
        "            # Filter the output to remove directories (which end with '/')\n",
        "            # and clean up empty lines.\n",
        "            file_names = [\n",
        "                line.strip()\n",
        "                for line in result.stdout.split('\\n')\n",
        "                if line.strip() and not line.endswith('/')\n",
        "            ]\n",
        "\n",
        "            if not file_names:\n",
        "                print(f\"âš ï¸ WARNING: Found 0 files in bucket {GCS_SOURCE}. Check the path or contents.\")\n",
        "            else:\n",
        "                print(f\"âœ… Success! Found {len(file_names)} files to process.\")\n",
        "\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"ðŸ›‘ ERROR running gsutil: {e.stderr}\")\n",
        "        except FileNotFoundError:\n",
        "            print(\"ðŸ›‘ ERROR: 'gsutil' command not found. Ensure the environment is configured correctly.\")\n",
        "\n",
        "# --- Logic for List of GCS Files ---\n",
        "elif 'List of GCS Files' in selected_option:\n",
        "\n",
        "    if not file_list_raw:\n",
        "        print(\"ðŸ›‘ ERROR: The list of GCS files cannot be empty.\")\n",
        "    else:\n",
        "        # Split the text area input into a list of file paths, cleaning up whitespace\n",
        "        file_names = [\n",
        "            line.strip()\n",
        "            for line in file_list_raw.split('\\n')\n",
        "            if line.strip() and line.startswith('gs://')\n",
        "        ]\n",
        "\n",
        "        if not file_names:\n",
        "            print(\"âš ï¸ WARNING: No valid GCS paths found in the list (must start with 'gs://').\")\n",
        "        else:\n",
        "            print(f\"âœ… Success! Loaded {len(file_names)} files directly from user input.\")\n",
        "\n",
        "# --- Final Check and Output ---\n",
        "if file_names:\n",
        "  if len(file_names) > 20:\n",
        "    print(\"ðŸ›‘ ERROR: The number of files to process exceeds 20.\")\n",
        "    sys.exit(1)\n",
        "  else:\n",
        "    print(\"-\" * 35)\n",
        "    print(f\"The first 3 files are:\")\n",
        "    for f in file_names[:3]:\n",
        "        print(f\"  - {f}\")\n",
        "    print(\"-\" * 35)\n",
        "    print(\"\\nðŸš€ Ready for processing! The file paths are stored in the 'file_names' list.\")\n",
        "else:\n",
        "    print(\"\\nâŒ Processing cannot continue. The 'file_names' list is empty.\")"
      ],
      "metadata": {
        "id": "rDxKjt2U55A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enable Google APIs"
      ],
      "metadata": {
        "id": "ihq_z_yrTvhJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CMDtMB49A5U"
      },
      "outputs": [],
      "source": [
        "!gcloud config set project {PROJECT_ID}\n",
        "!gcloud services enable visionai.googleapis.com\n",
        "!gcloud services enable videointelligence.googleapis.com"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PL0YkrmiT1Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gIcJvfN2XAz"
      },
      "source": [
        "### Step 1: Provision a corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ALIg9FV6t-I"
      },
      "source": [
        "Before you can add any content, you must first provision a \"Corpus\". Think of a Corpus as your dedicated, private container within our system. When you run the \"Provision Corpus\" section, you are telling our system to prepare all the necessary infrastructure for you. This includes setting up the indexing pipeline (which organizes your data for fast retrieval) and the search serving pipeline (which handles incoming search requests). This is a foundational, one-time action for each collection of content you wish to manage.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "| Step | Approximately time |\n",
        "| :--- | :--- |\n",
        "| Step 1.1: CreateCorpus API | ~ 3min |\n",
        "| Step 1.2: CreateIndex API | 30min - 60min |\n",
        "| Step 1.3: CreateIndexEndpoint API | ~ 5min |\n",
        "| Step 1.4: DeployIndexEndpoint |  30min - 60min |\n",
        "\n",
        "---\n",
        "\n",
        "ðŸ›‘ NOTE: You only need to run this step once. Please save the created CorpusID/IndexID/IndexEndpointID for the following steps.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predefined Utils for Provision\n",
        "CreateCorpus, CreateIndex, CreateIndexEndpoint, DeployIndex"
      ],
      "metadata": {
        "id": "Y5X5vuwzUymI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjEU3H0zdkZp"
      },
      "outputs": [],
      "source": [
        "def create_corpus_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    project_number: str,\n",
        "    location_id: str,\n",
        "    display_name: str,\n",
        "    description: str,\n",
        "    search_capabilities: List[visionai_v1.SearchCapability],\n",
        "    corpus_type: visionai_v1.Corpus.Type = visionai_v1.Corpus.Type.VIDEO_ON_DEMAND,\n",
        "    timeout_seconds: int = 7200\n",
        ") -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Submits a request to create a new Corpus in the Vision AI Warehouse.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        project_number: The GCP project number.\n",
        "        location_id: The GCP location (e.g., \"us-central1\").\n",
        "        display_name: The human-readable name for the new corpus.\n",
        "        description: A description for the new corpus.\n",
        "        search_capabilities: A list of search capabilities to enable.\n",
        "        corpus_type: The type of corpus (e.g., VIDEO_ON_DEMAND).\n",
        "        timeout_seconds: Max time to wait for the operation to complete.\n",
        "\n",
        "    Returns:\n",
        "        The resource name of the newly created corpus (e.g., \".../corpora/...\"),\n",
        "        or None if creation failed.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(f\"Initializing corpus with name: '{display_name}'\")\n",
        "        parent = f\"projects/{project_number}/locations/{location_id}\"\n",
        "\n",
        "        corpus = visionai_v1.Corpus(\n",
        "            display_name=display_name,\n",
        "            description=description,\n",
        "            type_=corpus_type,\n",
        "            search_capability_setting=visionai_v1.SearchCapabilitySetting(\n",
        "                search_capabilities=search_capabilities\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        request = visionai_v1.CreateCorpusRequest(\n",
        "            parent=parent,\n",
        "            corpus=corpus,\n",
        "        )\n",
        "\n",
        "        logging.info(f\"Submitting create_corpus request to parent: {parent}...\")\n",
        "        operation = client.create_corpus(request=request)\n",
        "\n",
        "        logging.info(f\"â³Waiting for operation to complete (timeout: {timeout_seconds}s)...\")\n",
        "        response = operation.result(timeout=timeout_seconds)\n",
        "\n",
        "        logging.info(f\"Successfully created corpus: {response.name}\")\n",
        "        logging.debug(f\"Full response: {response}\")\n",
        "        return response.name\n",
        "\n",
        "    except TimeoutError:\n",
        "        logging.error(f\"Operation timed out after {timeout_seconds} seconds. \"\n",
        "                      \"The corpus might still be creating in the background.\")\n",
        "        return None\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"An API error occurred during corpus creation: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected (non-API) error occurred: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "\n",
        "def create_index_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    parent_corpus_name: str,\n",
        "    display_name: str,\n",
        "    description: str,\n",
        "    timeout_seconds: int = 7200\n",
        ") -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Submits a request to create a new Index in the Vision AI Warehouse.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        parent_corpus_name: The resource name of the corpus (e.g., \"projects/.../corpora/...\").\n",
        "        display_name: The human-readable name for the new index.\n",
        "        description: A description for the new index.\n",
        "        timeout_seconds: Max time to wait for the operation to complete.\n",
        "\n",
        "    Returns:\n",
        "        The resource name of the newly created index (e.g., \".../indexes/...\"),\n",
        "        or None if creation failed.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(f\"Initializing index with name: '{display_name}'\")\n",
        "        index = visionai_v1.Index(\n",
        "            display_name=display_name,\n",
        "            description=description,\n",
        "        )\n",
        "        request = visionai_v1.CreateIndexRequest(\n",
        "            parent=parent_corpus_name,\n",
        "            index=index,\n",
        "        )\n",
        "\n",
        "        logging.info(f\"Submitting create_index request to parent: {parent_corpus_name}...\")\n",
        "        operation = client.create_index(request=request)\n",
        "\n",
        "        logging.info(f\"Operation submitted. Operation name: {operation._operation.name}\")\n",
        "        logging.info(f\"â³Waiting for operation to complete (timeout: {timeout_seconds}s)...\")\n",
        "        response = operation.result(timeout=timeout_seconds)\n",
        "        logging.info(f\"Successfully created index: {response.name}\")\n",
        "        logging.debug(f\"Full response: {response}\")\n",
        "        return response.name\n",
        "\n",
        "    except TimeoutError:\n",
        "        logging.error(f\"Operation timed out after {timeout_seconds} seconds. \"\n",
        "                      \"The index might still be creating in the background.\")\n",
        "        return None\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"An API error occurred during index creation: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected (non-API) error occurred: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "\n",
        "def create_index_endpoint_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    project_number: str,\n",
        "    location_id: str,\n",
        "    display_name: str,\n",
        "    description: str,\n",
        "    timeout_seconds: int = 7200\n",
        ") -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Submits a request to create a new IndexEndpoint in the Vision AI Warehouse.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        project_number: The GCP project number.\n",
        "        location_id: The GCP location (e.g., \"us-central1\").\n",
        "        display_name: The human-readable name for the new index.\n",
        "        description: A description for the new index.\n",
        "        timeout_seconds: Max time to wait for the operation to complete.\n",
        "\n",
        "    Returns:\n",
        "        The resource name of the newly created index (e.g., \".../indexes/...\"),\n",
        "        or None if creation failed.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(f\"Initializing indexEndpoint with name: '{display_name}'\")\n",
        "        parent = f\"projects/{project_number}/locations/{location_id}\"\n",
        "\n",
        "        index_endpoint = visionai_v1.IndexEndpoint(\n",
        "            display_name=display_name,\n",
        "            description=description,\n",
        "        )\n",
        "\n",
        "        request = visionai_v1.CreateIndexEndpointRequest(\n",
        "            parent=parent,\n",
        "            index_endpoint=index_endpoint,\n",
        "        )\n",
        "\n",
        "        logging.info(f\"Submitting create_index_endpoint request to parent: {parent}...\")\n",
        "        operation = client.create_index_endpoint(request=request)\n",
        "\n",
        "        logging.info(f\"Operation submitted. Operation name: {operation._operation.name}\")\n",
        "        logging.info(f\"â³Waiting for operation to complete (timeout: {timeout_seconds}s)...\")\n",
        "        response = operation.result(timeout=timeout_seconds)\n",
        "\n",
        "        logging.info(f\"Successfully created index_endpoint: {response.name}\")\n",
        "        logging.debug(f\"Full response: {response}\")\n",
        "        return response.name\n",
        "\n",
        "    except TimeoutError:\n",
        "        logging.error(f\"Operation timed out after {timeout_seconds} seconds. \"\n",
        "                      \"The index_endpoint might still be creating in the background.\")\n",
        "        return None\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"An API error occurred during index endpoint creation: {e}. Will retry.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected (non-API) error occurred: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "\n",
        "def deploy_index_endpoint_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    index_endpoint_name: str,\n",
        "    index_name: str,\n",
        "    timeout_seconds: int = 7200\n",
        ") -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Submits a request to deploy the index to the index endpoint.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        index_endpoint_name: The resource name of the index_endpoint (e.g., \"projects/.../indexEndpoints/...\").\n",
        "        index_name: The resource name of the index (e.g., \"projects/.../indexes/...\").\n",
        "        timeout_seconds: Max time to wait for the operation to complete.\n",
        "\n",
        "    Returns:\n",
        "        The resource name of the newly created index (e.g., \".../indexes/...\"),\n",
        "        or None if creation failed.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(f\"Deploying indexEndpoint with name: '{index_endpoint_name} with index {index_name}'\")\n",
        "\n",
        "        deployed_index = visionai_v1.DeployedIndex()\n",
        "        deployed_index.index = index_name\n",
        "\n",
        "        request = visionai_v1.DeployIndexRequest(\n",
        "            index_endpoint=index_endpoint_name,\n",
        "            deployed_index=deployed_index,\n",
        "        )\n",
        "\n",
        "        logging.info(f\"Submitting deploy_index request...\")\n",
        "        operation = client.deploy_index(request=request)\n",
        "        logging.info(f\"Operation submitted. Operation name: {operation._operation.name}\")\n",
        "\n",
        "        logging.info(f\"â³Waiting for operation to complete (timeout: {timeout_seconds}s)...\")\n",
        "        response = operation.result(timeout=timeout_seconds)\n",
        "\n",
        "        logging.info(f\"Successfully deploy index_endpoint\")\n",
        "        logging.debug(f\"Full response: {response}\")\n",
        "        return operation._operation.name\n",
        "\n",
        "    except TimeoutError:\n",
        "        logging.error(f\"Operation timed out after {timeout_seconds} seconds. \"\n",
        "                      \"The index_endpoint might still be creating in the background.\")\n",
        "        return None\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"An API error occurred during index creation: {e}. Expected if this is a brand new project. Will retry after the first corpus is created.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected (non-API) error occurred: {e}\", exc_info=True)\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxLS0XVaBZXi"
      },
      "source": [
        "#### Provision\n",
        "You can use this section to trigger creation of corpus, index and index endpoint together automatically.\n",
        "\n",
        "\n",
        "If any step fails, you can check which step fails, and call the corresponding API to rerun it or check the operation status manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCeN2YbVDO9X",
        "cellView": "code"
      },
      "outputs": [],
      "source": [
        "need_provision = (choice_widget.value == 'Create New Corpus')\n",
        "\n",
        "if not need_provision:\n",
        "    # IDs come from the widget input fields\n",
        "    corpus_id = corpus_input.value\n",
        "    index_id = index_input.value\n",
        "    index_endpoint_id = endpoint_input.value\n",
        "\n",
        "    parent_name=f\"projects/{PROJECT_NUMBER}/locations/{LOCATION_ID}\"\n",
        "    corpus_name = f\"{parent_name}/corpora/{corpus_id}\"\n",
        "    index_name = f\"{parent_name}/corpora/{corpus_id}/indexes/{index_id}\"\n",
        "    index_endpoint_name = f\"{parent_name}/indexEndpoints/{index_endpoint_id}\"\n",
        "    logging.info(\"âœ… No Provision is needed as existing ids are used.\")\n",
        "    logging.info (f\"Corpus         : {corpus_name}\")\n",
        "    logging.info (f\"Index          : {index_name}\")\n",
        "    logging.info (f\"Index Endpoint : {index_endpoint_name}\")\n",
        "else:\n",
        "  param_corpus_display_name = \"python colab test corpus\" # @param {type: \"string\"}\n",
        "  param_corpus_description = \"python colab test corpus\" # @param {type: \"string\"}\n",
        "  param_index_display_name = \"python colab test index\" # @param {type: \"string\"}\n",
        "  param_index_description = \"python colab test index\" # @param {type: \"string\"}\n",
        "  param_index_endpoint_display_name = \"python colab test endpoint\" # @param {type: \"string\"}\n",
        "  param_index_endpoint_description = \"python colab test endpoint\" # @param {type: \"string\"}\n",
        "\n",
        "  # --- Default Search Capabilities ---\n",
        "  DEFAULT_SEARCH_CAPABILITY = visionai_v1.SearchCapability(\n",
        "      type_=visionai_v1.SearchCapability.Type.DEFAULT_SEARCH\n",
        "  )\n",
        "  if IS_AMERICAN_FOOTBALL:\n",
        "    DEFAULT_SEARCH_CAPABILITY.default_search_config=visionai_v1.SearchCapability.DefaultSearchConfig(\n",
        "        model_id=\"sports-1.0\"\n",
        "    )\n",
        "  # --- Speech Transcription ---\n",
        "  SPEECH_SEARCH_CAPABILITY = visionai_v1.SearchCapability(\n",
        "      type_=visionai_v1.SearchCapability.Type.MODEL_GARDEN_MODEL_POWERED_SEARCH,\n",
        "      model_garden_model_powered_search_config=visionai_v1.SearchCapability.ModelGardenModelPoweredSearchConfig(\n",
        "          model_resource_id=\"video-speech-transcription@001\"\n",
        "      )\n",
        "  )\n",
        "  # --- Text Detections ---\n",
        "  TEXT_SEARCH_CAPABILITY = visionai_v1.SearchCapability(\n",
        "      type_=visionai_v1.SearchCapability.Type.MODEL_GARDEN_MODEL_POWERED_SEARCH,\n",
        "      model_garden_model_powered_search_config=visionai_v1.SearchCapability.ModelGardenModelPoweredSearchConfig(\n",
        "          model_resource_id=\"video-text-detection@001\"\n",
        "      )\n",
        "  )\n",
        "  DEFAULT_VIDEO_ON_DEMAND_CAPABILITIES = [\n",
        "      DEFAULT_SEARCH_CAPABILITY,\n",
        "      SPEECH_SEARCH_CAPABILITY,\n",
        "      TEXT_SEARCH_CAPABILITY\n",
        "  ]\n",
        "\n",
        "  def run_provision_warehouse_pipeline(\n",
        "      client: visionai_v1.WarehouseClient,\n",
        "      project_number: str,\n",
        "      location_id: str,\n",
        "      corpus_display_name: str,\n",
        "      corpus_description: str,\n",
        "      index_display_name: str,\n",
        "      index_description: str,\n",
        "      index_endpoint_display_name: str,\n",
        "      index_endpoint_description: str,\n",
        "      default_search_capabilities: List[visionai_v1.SearchCapability],\n",
        "      max_parallel_workers: int = 2\n",
        "  ) -> Optional[Dict[str, str]]:\n",
        "      \"\"\"\n",
        "      Runs the full pipeline to create and deploy a Vision AI Warehouse index.\n",
        "\n",
        "      Steps:\n",
        "      1.  (Parallel) Create Corpus\n",
        "      2.  (Parallel/Sequential) Create IndexEndpoint. If it is a project without\n",
        "          any corpus created yet, this step will be retried to run after the\n",
        "          corpus is created.\n",
        "      3.  (Sequential) Create Index (depends on Corpus)\n",
        "      4.  (Sequential) Deploy Index (depends on Index and IndexEndpoint)\n",
        "\n",
        "      Args:\n",
        "          client: The initialized WarehouseClient.\n",
        "          project_number: The GCP project number.\n",
        "          location_id: The GCP location (e.g., \"us-central1\").\n",
        "          corpus_display_name: Display name for the new corpus.\n",
        "          corpus_description: Description for the new corpus.\n",
        "          index_display_name: Display name for the new index.\n",
        "          index_description: Description for the new index.\n",
        "          index_endpoint_display_name: Display name for the new index endpoint.\n",
        "          index_endpoint_description: Description for the new index endpoint.\n",
        "          max_parallel_workers: Max threads to use for parallel steps.\n",
        "\n",
        "      Returns:\n",
        "          A dictionary containing the resource names of all created assets,\n",
        "          or None if any step failed.\n",
        "      \"\"\"\n",
        "      logging.info(\"--- Starting Provision Warehouse Pipeline ---\")\n",
        "\n",
        "      corpus_name: Optional[str] = None\n",
        "      index_name: Optional[str] = None\n",
        "      index_endpoint_name: Optional[str] = None\n",
        "      deployed_index_endpoint: Optional[str] = None\n",
        "\n",
        "      try:\n",
        "          with concurrent.futures.ThreadPoolExecutor(max_workers=max_parallel_workers) as executor:\n",
        "\n",
        "              # --- Phase 1: Run CreateCorpus and CreateIndexEndpoint ---\n",
        "              logging.info(\"Phase 1: Submitting CreateCorpus and CreateIndexEndpoint.\")\n",
        "\n",
        "              # Submit Task (CreateCorpus)\n",
        "              future_corpus = executor.submit(\n",
        "                  create_corpus_robust,\n",
        "                  client=client,\n",
        "                  project_number=project_number,\n",
        "                  location_id=location_id,\n",
        "                  display_name=corpus_display_name,\n",
        "                  description=corpus_description,\n",
        "                  search_capabilities=DEFAULT_VIDEO_ON_DEMAND_CAPABILITIES\n",
        "              )\n",
        "\n",
        "              # Submit Task (CreateIndexEndpoint)\n",
        "              future_index_endpoint = executor.submit(\n",
        "                  create_index_endpoint_robust,\n",
        "                  client=client,\n",
        "                  project_number=project_number,\n",
        "                  location_id=location_id,\n",
        "                  display_name=index_endpoint_display_name,\n",
        "                  description=index_endpoint_description\n",
        "              )\n",
        "\n",
        "              # --- Barrier: Wait for Phase 1 to complete ---\n",
        "              # .result() blocks until its specific task is done and returns the value\n",
        "\n",
        "              logging.info(\"Waiting for CreateCorpus to complete...\")\n",
        "              corpus_name = future_corpus.result()\n",
        "\n",
        "              logging.info(\"Waiting for CreateIndexEndpoint to complete...\")\n",
        "              index_endpoint_name = future_index_endpoint.result()\n",
        "\n",
        "              # --- Check for failures before proceeding ---\n",
        "              if not corpus_name:\n",
        "                  logging.error(\"âŒPhase 1 failed. One or more parallel tasks did not return a resource name. Aborting.\")\n",
        "                  if not corpus_name: logging.error(\"  > create_corpus_robust failed.\")\n",
        "                  return None\n",
        "              if not index_endpoint_name:\n",
        "                  logging.info(\"Retry create index endpoint which need to run after the first corpus is created in the project.\")\n",
        "                  # --- Waits as CreateCorpus will provision IAM permissions which needs a short period to take effect.\n",
        "                  time.sleep(240)\n",
        "                  index_endpoint_name = create_index_endpoint_robust(\n",
        "                    client=client,\n",
        "                    project_number=project_number,\n",
        "                    location_id=location_id,\n",
        "                    display_name=index_endpoint_display_name,\n",
        "                    description=index_endpoint_description)\n",
        "                  if not index_endpoint_name:\n",
        "                    logging.error(\"âŒPhase 1 failed. One or more parallel tasks did not return a resource name. Aborting.\")\n",
        "                    logging.error(\"  > create_index_endpoint_robust failed.\")\n",
        "                    return None\n",
        "\n",
        "              logging.info(\"âœ…Phase 1 complete.\")\n",
        "              logging.info(f\"  > Corpus Name: {corpus_name}\")\n",
        "              logging.info(f\"  > Index Endpoint Name: {index_endpoint_name}\")\n",
        "\n",
        "          # --- Phase 2: Run CreateIndex (depends on corpus_name) ---\n",
        "          # This runs sequentially after Phase 1\n",
        "          logging.info(\"Phase 2: Submitting CreateIndex...\")\n",
        "          index_name = create_index_robust(\n",
        "              client=client,\n",
        "              parent_corpus_name=corpus_name,\n",
        "              display_name=index_display_name,\n",
        "              description=index_description\n",
        "          )\n",
        "\n",
        "          if not index_name:\n",
        "              logging.error(\"âŒPhase 2 (CreateIndex) failed. Aborting pipeline.\")\n",
        "              return None\n",
        "\n",
        "          logging.info(\"âœ…Phase 2 complete.\")\n",
        "          logging.info(f\"  > Index Name: {index_name}\")\n",
        "\n",
        "          # --- Phase 3: Run DeployIndexEndpoint (depends on index_name and index_endpoint_name) ---\n",
        "          logging.info(\"Phase 3: Submitting DeployIndexEndpoint...\")\n",
        "\n",
        "          deployed_index_endpoint = deploy_index_endpoint_robust(\n",
        "              client=client,\n",
        "              index_endpoint_name=index_endpoint_name,\n",
        "              index_name=index_name\n",
        "          )\n",
        "\n",
        "          if not deployed_index_endpoint:\n",
        "              logging.error(\"âŒPhase 3 (DeployIndexEndpoint) failed. Pipeline finished with errors.\")\n",
        "              return None\n",
        "\n",
        "          logging.info(\"--- ðŸŽ‰Full Warehouse Pipeline Succeeded!ðŸŽ‰ ---\")\n",
        "          logging.info(f\"  > Corpus: {corpus_name}\")\n",
        "          logging.info(f\"  > Index: {index_name}\")\n",
        "          logging.info(f\"  > Index Endpoint: {index_endpoint_name}\")\n",
        "          logging.info(f\"  > Deployed Status: Index is deployed to endpoint.\")\n",
        "\n",
        "          # Return all the created resource names\n",
        "          return {\n",
        "              \"corpus_name\": corpus_name,\n",
        "              \"index_name\": index_name,\n",
        "              \"index_endpoint_name\": index_endpoint_name,\n",
        "          }\n",
        "\n",
        "      except Exception as e:\n",
        "          logging.critical(f\"A critical error occurred in the pipeline executor: {e}\", exc_info=True)\n",
        "          return None\n",
        "\n",
        "  if 'warehouse_client' in locals() and 'PROJECT_NUMBER' in locals() and 'LOCATION_ID' in locals():\n",
        "      pipeline_results = run_provision_warehouse_pipeline(\n",
        "          client=warehouse_client,\n",
        "          project_number=PROJECT_NUMBER,\n",
        "          location_id=LOCATION_ID,\n",
        "          corpus_display_name=param_corpus_display_name,\n",
        "          corpus_description=param_corpus_description,\n",
        "          index_display_name=param_index_display_name,\n",
        "          index_description=param_index_description,\n",
        "          index_endpoint_display_name=param_index_endpoint_display_name,\n",
        "          index_endpoint_description=param_index_endpoint_description,\n",
        "          default_search_capabilities=DEFAULT_VIDEO_ON_DEMAND_CAPABILITIES\n",
        "      )\n",
        "\n",
        "      if pipeline_results:\n",
        "          logging.info(f\"ðŸŽ‰ðŸ¥³Pipeline completed successfully!\")\n",
        "          logging.info(f\"Corpus: {pipeline_results.get('corpus_name')}\")\n",
        "          logging.info(f\"Index: {pipeline_results.get('index_name')}\")\n",
        "          logging.info(f\"Index Endpoint: {pipeline_results.get('index_endpoint_name')}\")\n",
        "          corpus_name = pipeline_results.get('corpus_name')\n",
        "          index_name = pipeline_results.get('index_name')\n",
        "          index_endpoint_name = pipeline_results.get('index_endpoint_name')\n",
        "      else:\n",
        "          logging.info(f\"âŒ Pipeline failed. Check logs above for errors.\")\n",
        "          sys.exit(1)\n",
        "  else:\n",
        "      logging.error(\"âŒ`warehouse_client`, `PROJECT_NUMBER`, or `LOCATION_ID` is not defined. \"\n",
        "                    \"Please run the initialization cells.\")\n",
        "      sys.exit(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ghMbrQhuEox"
      },
      "source": [
        "### Step 2: Video Processing\n",
        "\n",
        "For each video, Vision Warehouse will run\n",
        "\n",
        "\n",
        "--------------------------------------\n",
        "\n",
        "\n",
        "| Step | Approximately time |\n",
        "| :--- | :--- |\n",
        "| CreateAsset API | Instance |\n",
        "| UploadAsset API | depends on the duration |\n",
        "| AnalyzeAsset API | depends on the duration |\n",
        "| IndexAsset API | a few minutes |\n",
        "\n",
        "> It also checks whether the video has audio track to decided whether trigger\n",
        "speech model for the asset. This is done by using ffprobe and UpdateAsset (to remove the speech model from the created asset).\n",
        "\n",
        "> From better user experience, we also create the default `title annotation` for each asset you created, the default title would be the **same** value of the GCS file name.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predefined Utils for ingesting video file"
      ],
      "metadata": {
        "id": "HWBJZQ1mvYqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Wrapper functions for CreateAsset, UploadAsset, AnalyzeAsset, IndexAsset, CreateDataSchema, CreateAnnotation"
      ],
      "metadata": {
        "id": "_EN7rZXswKFa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtO_BFe0yRp-"
      },
      "outputs": [],
      "source": [
        "def create_asset_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    parent_corpus_name: str,\n",
        "    search_capability_contexts: List[visionai_v1.SearchCapabilityContext],\n",
        "    ignore_already_exists: bool = False\n",
        ") -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Creates a new Asset resource within a corpus.\n",
        "    This is a non-LRO, synchronous call.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        parent_corpus_name: The resource name of the corpus to create the asset in.\n",
        "\n",
        "    Returns:\n",
        "        The resource name of the newly created asset, or None if creation failed.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(f\"Creating asset in corpus '{parent_corpus_name}'...\")\n",
        "\n",
        "        asset = visionai_v1.Asset(\n",
        "            search_capability_contexts=search_capability_contexts\n",
        "        )\n",
        "\n",
        "        request = visionai_v1.CreateAssetRequest(\n",
        "            parent=parent_corpus_name,\n",
        "            asset=asset,\n",
        "        )\n",
        "\n",
        "        response = client.create_asset(request=request)\n",
        "\n",
        "        logging.info(f\"Successfully created asset: {response.name}\")\n",
        "        return response.name\n",
        "\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while creating asset: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "\n",
        "def create_data_schema_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    parent_corpus_name: str,\n",
        "    data_schema: visionai_v1.DataSchema,\n",
        "    ignore_already_exists: bool = False\n",
        ") -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Creates a new DataSchema resource within a corpus.\n",
        "    This is a non-LRO, synchronous call.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        parent_corpus_name: The resource name of the corpus.\n",
        "        data_schema: The DataSchema object to create.\n",
        "\n",
        "    Returns:\n",
        "        The resource name of the newly created data schema, or None if creation failed.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(f\"Creating data schema {data_schema.key} in corpus '{parent_corpus_name}'...\")\n",
        "\n",
        "        request = visionai_v1.CreateDataSchemaRequest(\n",
        "            parent=parent_corpus_name,\n",
        "            data_schema=data_schema,\n",
        "        )\n",
        "\n",
        "        response = client.create_data_schema(request=request)\n",
        "\n",
        "        logging.info(f\"Successfully created data schema: {response.name}\")\n",
        "        return response.name\n",
        "\n",
        "    except google_exceptions.AlreadyExists as e:\n",
        "        logging.warning(f\"Data schema with key '{data_schema.key}' already exists in corpus '{parent_corpus_name}'. Continuing.\")\n",
        "        return f\"{parent_corpus_name}/dataschemas/{data_schema.key}\"\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while creating data schema: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "def create_annotation_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    parent_asset_name: str,\n",
        "    annotation: visionai_v1.Annotation,\n",
        "    ignore_already_exists: bool = False\n",
        ") -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Creates a new Annotation resource within an asset.\n",
        "    This is a non-LRO, synchronous call.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        parent_asset_name: The resource name of the asset to annotate.\n",
        "        annotation: The Annotation object to create.\n",
        "\n",
        "    Returns:\n",
        "        The resource name of the newly created annotation, or None if creation failed.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(f\"Creating annotation in asset '{parent_asset_name}'...\")\n",
        "\n",
        "        request = visionai_v1.CreateAnnotationRequest(\n",
        "            parent=parent_asset_name,\n",
        "            annotation=annotation,\n",
        "        )\n",
        "\n",
        "        response = client.create_annotation(request=request)\n",
        "\n",
        "        logging.info(f\"Successfully created annotation: {response.name}\")\n",
        "        return response.name\n",
        "\n",
        "    except google_exceptions.AlreadyExists as e:\n",
        "        logging.warning(f\"Annotation '{annotation.key}' already exists in asset '{parent_asset_name}'. Continuing.\")\n",
        "        return f\"{annotation.name}\"\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while creating annotation: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "def upload_asset_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    asset_name: str,\n",
        "    asset_gcs_uri: str,\n",
        "    timeout_seconds: int = TIMEOUT_SECS\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Uploads an asset (e.g., video) from GCS into the Warehouse.\n",
        "    This is a long-running operation.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        asset_name: The resource name of the *existing* asset placeholder.\n",
        "        asset_gcs_uri: The \"gs://\" path to the media file in GCS.\n",
        "        timeout_seconds: Max time to wait for the operation to complete.\n",
        "\n",
        "    Returns:\n",
        "        True on success, False on failure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(f\"Uploading asset from '{asset_gcs_uri}' to asset '{asset_name}'...\")\n",
        "\n",
        "        request = visionai_v1.UploadAssetRequest(\n",
        "            name=asset_name,\n",
        "            asset_source=visionai_v1.AssetSource(\n",
        "                asset_gcs_source=visionai_v1.AssetSource.AssetGcsSource(\n",
        "                    gcs_uri=asset_gcs_uri\n",
        "                )\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        operation = client.upload_asset(request=request)\n",
        "\n",
        "        logging.info(f\"Operation submitted. Operation name: {operation._operation.name}\")\n",
        "\n",
        "        logging.info(f\"â³Waiting for upload to complete (timeout: {timeout_seconds}s)...\")\n",
        "        response: visionai_v1.UploadAssetResponse = operation.result(timeout=timeout_seconds)\n",
        "\n",
        "        logging.info(f\"Successfully uploaded asset: {asset_name}\")\n",
        "        logging.debug(f\"Full response: {response}\")\n",
        "        return True\n",
        "\n",
        "    except TimeoutError:\n",
        "        logging.error(f\"Operation timed out after {timeout_seconds} seconds. \"\n",
        "                      \"The asset upload might still be in progress.\")\n",
        "        return False\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while uploading asset: {e}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return False\n",
        "\n",
        "def upload_asset_robust_with_retry(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    asset_name: str,\n",
        "    asset_gcs_uri: str,\n",
        "    timeout_seconds: int = TIMEOUT_SECS,\n",
        "    retry_cnt: int = 3,\n",
        ") -> bool:\n",
        "    cnt = 0\n",
        "    uploaded = upload_asset_robust(client, asset_name, asset_gcs_uri, timeout_seconds)\n",
        "    while not uploaded and cnt < retry_cnt:\n",
        "        logging.info(f\"Retrying upload asset for {asset_gcs_uri}\")\n",
        "        uploaded = upload_asset_robust(client, asset_name, asset_gcs_uri, timeout_seconds)\n",
        "        cnt = cnt + 1\n",
        "    return uploaded\n",
        "\n",
        "\n",
        "def analyze_asset_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    asset_name: str,\n",
        "    timeout_seconds: int = TIMEOUT_SECS\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Runs analysis (e.g., speech-to-text) on an uploaded asset.\n",
        "    This is a long-running operation.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        asset_name: The resource name of the asset to analyze.\n",
        "        timeout_seconds: Max time to wait for the operation to complete.\n",
        "\n",
        "    Returns:\n",
        "        True on success, False on failure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(f\"Analyzing asset: {asset_name}...\")\n",
        "\n",
        "        request = visionai_v1.AnalyzeAssetRequest(\n",
        "            name=asset_name,\n",
        "        )\n",
        "\n",
        "        operation = client.analyze_asset(request=request)\n",
        "\n",
        "        logging.info(f\"Operation submitted. Operation name: {operation._operation.name}\")\n",
        "\n",
        "        logging.info(f\"â³Waiting for analysis to complete (timeout: {timeout_seconds}s)...\")\n",
        "        response: visionai_v1.AnalyzeAssetResponse = operation.result(timeout=timeout_seconds)\n",
        "\n",
        "        logging.info(f\"Successfully analyzed asset: {asset_name}\")\n",
        "        logging.debug(f\"Full response: {response}\")\n",
        "        return True\n",
        "\n",
        "    except TimeoutError:\n",
        "        logging.error(f\"Operation timed out after {timeout_seconds} seconds. \"\n",
        "                      \"The asset analysis might still be in progress.\")\n",
        "        return False\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while analyzing asset: {e}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return False\n",
        "\n",
        "\n",
        "def index_asset_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    asset_name: str,\n",
        "    index_name: str,\n",
        "    index_asset_level_only: bool = False,\n",
        "    timeout_seconds: int = TIMEOUT_SECS\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Indexes an asset, making its contents searchable.\n",
        "    This is a long-running operation.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        asset_name: The resource name of the asset to index.\n",
        "        timeout_seconds: Max time to wait for the operation to complete.\n",
        "\n",
        "    Returns:\n",
        "        True on success, False on failure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(f\"Indexing asset: {asset_name}...\")\n",
        "\n",
        "        request = visionai_v1.IndexAssetRequest(\n",
        "            name=asset_name,\n",
        "            index_asset_level_only=index_asset_level_only,\n",
        "            index=index_name,\n",
        "        )\n",
        "\n",
        "        operation = client.index_asset(request=request)\n",
        "\n",
        "        logging.info(f\"Operation submitted. Operation name: {operation._operation.name}\")\n",
        "\n",
        "        logging.info(f\"â³Waiting for indexing to complete (timeout: {timeout_seconds}s)...\")\n",
        "        response: visionai_v1.IndexAssetResponse = operation.result(timeout=timeout_seconds)\n",
        "\n",
        "        logging.info(f\"Successfully indexed asset: {asset_name}\")\n",
        "        logging.debug(f\"Full response: {response}\")\n",
        "        return True\n",
        "\n",
        "    except TimeoutError:\n",
        "        logging.error(f\"Operation timed out after {timeout_seconds} seconds. \"\n",
        "                      \"The asset indexing might still be in progress.\")\n",
        "        return False\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while indexing asset: {e}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return False\n",
        "\n",
        "def generate_retrieval_url_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    asset_name: str,\n",
        ") -> str:\n",
        "    try:\n",
        "        request = visionai_v1.GenerateRetrievalUrlRequest(\n",
        "            name=asset_name,\n",
        "        )\n",
        "\n",
        "        response = client.generate_retrieval_url(request=request)\n",
        "        logging.debug(f\"Full response: {response}\")\n",
        "        return response.signed_uri\n",
        "\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while retrieving uri: {e}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return False\n",
        "\n",
        "def update_asset_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    asset_name: str,\n",
        "    search_capability_contexts: List[visionai_v1.SearchCapabilityContext],\n",
        ") -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Creates a new Asset resource within a corpus.\n",
        "    This is a non-LRO, synchronous call.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        parent_corpus_name: The resource name of the corpus to create the asset in.\n",
        "\n",
        "    Returns:\n",
        "        The resource name of the newly created asset, or None if creation failed.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(f\"Updating asset in corpus '{asset_name}'...\")\n",
        "\n",
        "        asset = visionai_v1.Asset(\n",
        "            name=asset_name,\n",
        "            search_capability_contexts=search_capability_contexts\n",
        "        )\n",
        "\n",
        "        request = visionai_v1.UpdateAssetRequest(\n",
        "            asset=asset,\n",
        "        )\n",
        "\n",
        "        response = client.update_asset(request=request)\n",
        "\n",
        "        logging.info(f\"Successfully updated asset: {response.name}\")\n",
        "        return response.name\n",
        "\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while creating asset: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Helper function for checking if video has any audio tracks"
      ],
      "metadata": {
        "id": "EFaXutXqwPwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import json\n",
        "import shlex\n",
        "\n",
        "def check_video_for_audio(gcs_signed_uri: str) -> Optional[bool]:\n",
        "    \"\"\"\n",
        "    Uses ffprobe to check if a video file referenced by a signed GCS URI\n",
        "    contains at least one audio stream.\n",
        "\n",
        "    Args:\n",
        "        gcs_signed_uri: The full, signed URI for the video file.\n",
        "\n",
        "    Returns:\n",
        "        True if an audio stream is found, False otherwise.\n",
        "    \"\"\"\n",
        "    command_args = [\n",
        "        'ffprobe',\n",
        "        '-v', 'error',\n",
        "        '-select_streams', 'a',\n",
        "        '-show_entries', 'stream=codec_type',\n",
        "        '-of', 'json',\n",
        "        gcs_signed_uri\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        process = subprocess.run(\n",
        "            command_args,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            check=True  # Raise an exception for non-zero exit codes (e.g., file not found)\n",
        "        )\n",
        "\n",
        "        # If no audio is found, the JSON might still be valid but with an empty 'streams' array.\n",
        "        # If the file is valid but has no audio, ffprobe should return a JSON object with \"streams\": []\n",
        "\n",
        "        # Handle cases where ffprobe returns nothing (e.g., completely corrupt file)\n",
        "        if not process.stdout.strip():\n",
        "            logging.error(\"Warning: ffprobe returned empty output.\")\n",
        "            return None\n",
        "\n",
        "        data = json.loads(process.stdout)\n",
        "\n",
        "        # Check if the 'streams' list contains any elements\n",
        "        if 'streams' in data and len(data['streams']) > 0:\n",
        "            logging.info(f\"âœ… Audio streams found: {len(data['streams'])}\")\n",
        "            return True\n",
        "        else:\n",
        "            logging.info(\"âŒ No audio streams found. Going to remove speech transcription model.\")\n",
        "            return False\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # Handle errors like 'file not found' or other ffprobe issues\n",
        "        logging.error(f\"Error running ffprobe (Exit Code {e.returncode}):\")\n",
        "        logging.error(f\"Stderr: {e.stderr.strip()}\")\n",
        "        return None\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        # Handle unexpected non-JSON output from ffprobe\n",
        "        logging.error(\"Error: Could not parse ffprobe output as JSON.\")\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "UP9yMq6zE4KC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Helper Function for Ingest One Video File"
      ],
      "metadata": {
        "id": "KXr3lD8MwVcN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wR--6FydvmoA"
      },
      "outputs": [],
      "source": [
        "@dataclasses.dataclass\n",
        "class Steps:\n",
        "  \"\"\"Represents the steps during ingestion.\"\"\"\n",
        "  gcs_file: str = ''\n",
        "  asset_name: str = ''\n",
        "\n",
        "  asset_created: bool = False\n",
        "  data_schema_created: bool = False\n",
        "  title_created: bool = False\n",
        "  asset_uploaded: bool = False\n",
        "  audio_verified: bool = False\n",
        "  asset_analyzed: bool = False\n",
        "  asset_indexed: bool = False\n",
        "\n",
        "\n",
        "# --- Setting for speech transcription.\n",
        "language_code= \"en-US\" # @param {type: \"string\"}\n",
        "audio_track = 0 # @param {type: \"number\"}\n",
        "\n",
        "# --- Default Search Capability Contexts ---\n",
        "default_track_info=visionai_v1.VideoIntelligienceContext.SpeechTranscriptionContext.TrackInfo(\n",
        "                    language_code=language_code,\n",
        "                    audio_tracks=[audio_track],\n",
        "                )\n",
        "SPEECH_SEARCH_CAPABILITY_CONTEXT = visionai_v1.SearchCapabilityContext(\n",
        "    model_garden_model_context=visionai_v1.SearchCapabilityContext.ModelGardenModelContext(\n",
        "        video_intelligence_context=visionai_v1.VideoIntelligienceContext(\n",
        "            speech_transcription_context=visionai_v1.VideoIntelligienceContext.SpeechTranscriptionContext(\n",
        "                track_infos=[default_track_info]\n",
        "            )\n",
        "        ),\n",
        "        model_resource_id=\"video-speech-transcription@001\"\n",
        "    )\n",
        ")\n",
        "TEXT_SEARCH_CAPABILITY_CONTEXT = visionai_v1.SearchCapabilityContext(\n",
        "    model_garden_model_context=visionai_v1.SearchCapabilityContext.ModelGardenModelContext(\n",
        "        model_resource_id=\"video-text-detection@001\"\n",
        "    )\n",
        ")\n",
        "DEFAULT_SEARCH_CAPABILITY_CONTEXTS = [\n",
        "    SPEECH_SEARCH_CAPABILITY_CONTEXT,\n",
        "    TEXT_SEARCH_CAPABILITY_CONTEXT,\n",
        "]\n",
        "DEFAULT_SEARCH_CAPABILITY_CONTEXTS_NO_SPEECH = [\n",
        "  TEXT_SEARCH_CAPABILITY_CONTEXT,\n",
        "]\n",
        "\n",
        "def ingest_asset_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    parent_corpus_name: str,\n",
        "    index_name: str,\n",
        "    asset_gcs_uri: str\n",
        ") -> Optional[Steps]:\n",
        "    \"\"\"\n",
        "    Runs a full 7-step pipeline to ingest a single asset.\n",
        "\n",
        "    Steps:\n",
        "    1. Create Asset (placeholder)\n",
        "    2. Create/Verify Data Schema (for 'title' annotation)\n",
        "    3. Create Annotation (for title)\n",
        "    4. Upload Asset\n",
        "    5. Check whether the video has audio, removing speech model from created\n",
        "       asset if no audio track.\n",
        "    6. Analyze Asset (run AI models)\n",
        "    7. Index Asset (make searchable)\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        parent_corpus_name: The resource name of the corpus.\n",
        "        asset_gcs_uri: The \"gs://\" path to the media file to upload.\n",
        "\n",
        "    Returns:\n",
        "        The resource name of the newly ingested asset, or None if any step failed.\n",
        "    \"\"\"\n",
        "    logging.info(f\"--- {asset_gcs_uri}: Starting Full Asset Ingestion ---\")\n",
        "\n",
        "    s = Steps(gcs_file=asset_gcs_uri)\n",
        "\n",
        "    # Extract filename from GCS path to use as the title\n",
        "    title_value = os.path.basename(asset_gcs_uri)\n",
        "\n",
        "    # --- Step 1: Create Asset Placeholder ---\n",
        "    logging.info(f\"{asset_gcs_uri}: Step 1/7: Creating asset\")\n",
        "    asset_name = create_asset_robust(\n",
        "        client=client,\n",
        "        parent_corpus_name=parent_corpus_name,\n",
        "        search_capability_contexts=DEFAULT_SEARCH_CAPABILITY_CONTEXTS,\n",
        "        ignore_already_exists=True  # Handle idempotency as requested\n",
        "    )\n",
        "    if not asset_name:\n",
        "        logging.error(f\"{asset_gcs_uri}: âŒStep 1/7 FAILED: Could not create asset placeholder. Aborting ingestion.\")\n",
        "        return s\n",
        "    logging.info(f\"{asset_gcs_uri}: âœ…Step 1/7 Successful. Asset Name: {asset_name}\")\n",
        "    s.asset_created = True\n",
        "    s.asset_name = asset_name\n",
        "\n",
        "    # --- Step 2: Create/Verify Data Schema ---\n",
        "    logging.info(f\"{asset_gcs_uri}: Step 2/7: Creating/Verifying 'title' data schema...\")\n",
        "    # Define a simple schema that includes a \"title\" key of type STRING\n",
        "    default_title_data_schame=visionai_v1.DataSchema(\n",
        "        key=\"title\",\n",
        "        schema_details=visionai_v1.DataSchemaDetails(\n",
        "            type_=visionai_v1.DataSchemaDetails.DataType.STRING,\n",
        "            granularity=visionai_v1.DataSchemaDetails.Granularity.GRANULARITY_ASSET_LEVEL,\n",
        "            search_strategy=visionai_v1.DataSchemaDetails.SearchStrategy(\n",
        "                search_strategy_type=visionai_v1.DataSchemaDetails.SearchStrategy.SearchStrategyType.SMART_SEARCH\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    schema_status = create_data_schema_robust(\n",
        "        client=client,\n",
        "        parent_corpus_name=parent_corpus_name,\n",
        "        data_schema=default_title_data_schame,\n",
        "        ignore_already_exists=True  # Handle idempotency as requested\n",
        "    )\n",
        "\n",
        "    if not schema_status:\n",
        "        logging.error(f\"{asset_gcs_uri}: âŒStep 2/7 FAILED: Could not create/verify data schema '{default_title_data_schame.key}'. Aborting ingestion.\")\n",
        "        return s\n",
        "    logging.info(f\"{asset_gcs_uri}: âœ…Step 2/7 Successful. Data schema '{default_title_data_schame.key}' status: {schema_status}\")\n",
        "    s.data_schema_created = True\n",
        "\n",
        "    # --- Step 3: Create Title Annotation ---\n",
        "    logging.info(f\"{asset_gcs_uri}: Step 3/7: Creating title annotation...\")\n",
        "    title_annotation = visionai_v1.Annotation(\n",
        "        name=f\"{asset_name}/annotations/title\",\n",
        "        user_specified_annotation=visionai_v1.UserSpecifiedAnnotation(\n",
        "            key=\"title\", # This key is defined in the schema from Step 2\n",
        "            value=visionai_v1.AnnotationValue(\n",
        "                str_value=title_value\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    annotation_name = create_annotation_robust(\n",
        "        client=client,\n",
        "        parent_asset_name=asset_name,\n",
        "        annotation=title_annotation,\n",
        "        ignore_already_exists=True  # Handle idempotency as requested\n",
        "    )\n",
        "\n",
        "    if not annotation_name:\n",
        "        logging.error(f\"{asset_gcs_uri}: âŒStep 3/7 FAILED: Could not create title annotation. Aborting ingestion.\")\n",
        "        return s\n",
        "    logging.info(f\"{asset_gcs_uri}: âœ…Step 3/7 Successful. Annotation status: {annotation_name}\")\n",
        "    s.title_created = True\n",
        "\n",
        "    # --- Step 4: Upload Asset  ---\n",
        "    logging.info(f\"{asset_gcs_uri}: Step 4/7: Uploading asset ...\")\n",
        "    upload_success = upload_asset_robust_with_retry(\n",
        "        client=client,\n",
        "        asset_name=asset_name,\n",
        "        asset_gcs_uri=asset_gcs_uri\n",
        "    )\n",
        "    if not upload_success:\n",
        "        logging.error(f\"{asset_gcs_uri}: âŒStep 4/7 FAILED: Could not upload asset. Aborting ingestion.\")\n",
        "        return s\n",
        "    logging.info(f\"{asset_gcs_uri}: âœ…Step 4/7 Successful. Asset uploaded.\")\n",
        "    s.asset_uploaded = True\n",
        "\n",
        "    # --- Step 5: Checks audio tracks ---\n",
        "    logging.info(f\"{asset_gcs_uri}: Step 5/7: Checking audio tracks ...\")\n",
        "\n",
        "    signed_url = generate_retrieval_url_robust(\n",
        "        client=client,\n",
        "        asset_name=asset_name\n",
        "    )\n",
        "    if signed_url:\n",
        "      logging.info(f\"{asset_gcs_uri}: Step 5/7 Retrieval URL: {signed_url}\")\n",
        "      has_audio = check_video_for_audio(signed_url)\n",
        "      if has_audio is None:\n",
        "        logging.error(f\"{asset_gcs_uri}: âŒStep 5/7 FAILED: ffprob failed. Move forward. Speech transcription model will fail.\")\n",
        "      else:\n",
        "        if not has_audio:\n",
        "          logging.info(f\"{asset_gcs_uri}: Step 5/7: No audio tracks. Removing speech model ...{asset_name}\")\n",
        "          asset_name = update_asset_robust(\n",
        "              client=client,\n",
        "              asset_name=asset_name,\n",
        "              search_capability_contexts=DEFAULT_SEARCH_CAPABILITY_CONTEXTS_NO_SPEECH,\n",
        "          )\n",
        "          if not asset_name:\n",
        "            logging.error(f\"{asset_gcs_uri}: âŒStep 5/7 FAILED: Could not update asset. Non blocking. Speech transcription model will fail.\")\n",
        "          else:\n",
        "            logging.info(f\"{asset_gcs_uri}: âœ…Step 5/7 Successful update asset. Asset Name: {asset_name}\")\n",
        "            s.audio_verified = True\n",
        "        else:\n",
        "          logging.info(f\"{asset_gcs_uri}: âœ…Step 5/7 Successful update asset. Asset Name: {asset_name}\")\n",
        "          s.audio_verified = True\n",
        "    else:\n",
        "       logging.error(f\"{asset_gcs_uri}: âŒStep 5/7 FAILED: Non blocking. Move forward. Speech transcription model will fail.\")\n",
        "\n",
        "    # --- Step 6: Analyze Asset ---\n",
        "    logging.info(f\"{asset_gcs_uri}: Step 6/7: Submitting asset for analysis...\")\n",
        "    analyze_success = analyze_asset_robust(\n",
        "        client=client,\n",
        "        asset_name=asset_name\n",
        "    )\n",
        "    if not analyze_success:\n",
        "        logging.error(f\"{asset_gcs_uri}: âŒStep 6/7 FAILED: Could not analyze asset. Move forward with indexing.\")\n",
        "    else:\n",
        "        logging.info(f\"{asset_gcs_uri}: âœ…Step 6/7 Successful. Asset analysis complete.\")\n",
        "        s.asset_analyzed = True\n",
        "\n",
        "\n",
        "    # --- Step 6: Index Asset ---\n",
        "    logging.info(\"Step 7/7: Submitting asset for indexing...\")\n",
        "    index_success = index_asset_robust(\n",
        "        client=client,\n",
        "        asset_name=asset_name,\n",
        "        index_name=index_name,\n",
        "        index_asset_level_only=False\n",
        "    )\n",
        "    if not index_success:\n",
        "        logging.error(f\"{asset_gcs_uri}: âŒStep 7/7 FAILED: Could not index asset. Aborting ingestion.\")\n",
        "        return s\n",
        "    logging.info(f\"{asset_gcs_uri}: âœ…Step 7/7 Successful. Asset indexed.\")\n",
        "    s.asset_indexed = True\n",
        "    return s"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ingest Videos"
      ],
      "metadata": {
        "id": "TnAfLUIjwkUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "executor = concurrent.futures.ThreadPoolExecutor(max_workers=8)\n",
        "new_asset_futures = []\n",
        "for gcs_file in file_names:\n",
        "    new_asset_futures.append(\n",
        "        executor.submit(\n",
        "            ingest_asset_robust,\n",
        "            warehouse_client,\n",
        "            corpus_name,\n",
        "            index_name,\n",
        "            gcs_file,\n",
        "        )\n",
        "    )\n",
        "done_or_error, _ = concurrent.futures.wait(\n",
        "    new_asset_futures, return_when=\"ALL_COMPLETED\"\n",
        ")\n",
        "asset_ingestion_statuses = []\n",
        "for done_future in done_or_error:\n",
        "    try:\n",
        "        status = done_future.result()\n",
        "        asset_ingestion_statuses.append(status)\n",
        "        statuses = [\n",
        "            status.asset_created,\n",
        "            status.data_schema_created,\n",
        "            status.title_created,\n",
        "            status.asset_uploaded,\n",
        "            status.audio_verified,\n",
        "            status.asset_analyzed,\n",
        "            status.asset_indexed,\n",
        "        ]\n",
        "\n",
        "        if not all(statuses):\n",
        "            logging.error(f\"âŒ Ingestion failed: {status}\")\n",
        "        else:\n",
        "            logging.info(f\"âœ… Ingestion succeeded: {status}\")\n",
        "    except Exception as e:\n",
        "        logging.exception(e)"
      ],
      "metadata": {
        "id": "Ltq6lS9DWt-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oteKq6t9X3vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Search"
      ],
      "metadata": {
        "id": "M_ZHmBe53sNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predefined Utils for rendering search results"
      ],
      "metadata": {
        "id": "gj4FW_gs3ngw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@dataclasses.dataclass\n",
        "class SearchResult:\n",
        "  \"\"\"Represents a search result entry.\"\"\"\n",
        "\n",
        "  asset_name: str = ''\n",
        "  start_seconds: float = 0\n",
        "  end_seconds: float = 0\n",
        "  signed_uri: str = ''\n",
        "\n",
        "  html: str = ''"
      ],
      "metadata": {
        "id": "E26w3Kfts2EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AttachVideoHtml(results):\n",
        "  top_results = []\n",
        "  for r in results:\n",
        "    video_html = \"\"\"\n",
        "    <video width=\"640\" height=\"360\" controls>\n",
        "        <source src=\"{}#t={},{}\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\".format(r.signed_uri, r.start_seconds, r.end_seconds)\n",
        "    r.html = video_html\n",
        "    top_results.append(r)\n",
        "  return top_results"
      ],
      "metadata": {
        "id": "N-z6WAOOMlNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RenderLink(uri):\n",
        "  return '<a href=\"{}\">Link</a>'.format(uri)\n"
      ],
      "metadata": {
        "id": "hquto-jdLYQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RenderResults(warehouse_client, response, top_k=5):\n",
        "  results = []\n",
        "  for i, item in enumerate(response):\n",
        "    if i >= top_k:\n",
        "      break\n",
        "    r = SearchResult(\n",
        "        asset_name=item.asset,\n",
        "        start_seconds=item.segment.start_time.timestamp(), # Changed from .seconds\n",
        "        end_seconds=item.segment.end_time.timestamp(),     # Changed from .seconds\n",
        "        signed_uri=generate_retrieval_url_robust(warehouse_client, item.asset),\n",
        "    )\n",
        "    results.append(r)\n",
        "\n",
        "  if not results:\n",
        "    logging.info(\"No matched search results for this query.\")\n",
        "    return\n",
        "\n",
        "  top_5 = AttachVideoHtml(\n",
        "      results\n",
        "  )\n",
        "\n",
        "  df = pd.DataFrame(top_5)\n",
        "  df['signed_uri'] = df['signed_uri'].apply(RenderLink)\n",
        "  html_table = df.to_html(escape=False)\n",
        "  display(HTML(html_table))"
      ],
      "metadata": {
        "id": "RhIw1LJwib_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_retrieval_url_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    asset_name: str,\n",
        ") -> str:\n",
        "    try:\n",
        "        request = visionai_v1.GenerateRetrievalUrlRequest(\n",
        "            name=asset_name,\n",
        "        )\n",
        "\n",
        "        response = client.generate_retrieval_url(request=request)\n",
        "        logging.debug(f\"Full response: {response}\")\n",
        "        return response.signed_uri\n",
        "\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while retrieving uri: {e}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return False"
      ],
      "metadata": {
        "id": "xmdQ9XMzZi9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Search with a query that match globally without criteria key restriction."
      ],
      "metadata": {
        "id": "_IB9eq7I3tyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"bikes\" # @param {type:\"string\"}\n",
        "\n",
        "request=visionai_v1.SearchIndexEndpointRequest(\n",
        "    text_query=query,\n",
        "    result_granularity=visionai_v1.SearchResultGranularity.SEARCH_RESULT_GRANULARITY_PARTITION_LEVEL,\n",
        "    index_endpoint=index_endpoint_name,\n",
        "    result_annotation_keys=[\"title\"],\n",
        ")\n",
        "\n",
        "response = warehouse_client.search_index_endpoint(request=request)\n",
        "print(f\"Search: {response}\")"
      ],
      "metadata": {
        "id": "SKd4HQmjkbIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RenderResults(warehouse_client, response, top_k=5)"
      ],
      "metadata": {
        "id": "Mg8kvtnu5dRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Search that matches the text detection results"
      ],
      "metadata": {
        "id": "nnA-HxtH5fNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"Google\" # @param {type:\"string\"}\n",
        "data_schema_key=\"mgm-video-text-detection-001.text\" # @param {type: \"string\"}\n",
        "\n",
        "request=visionai_v1.SearchIndexEndpointRequest(\n",
        "    text_query=query,\n",
        "    criteria=[visionai_v1.Criteria(\n",
        "        field=data_schema_key,\n",
        "        text_array=visionai_v1.StringArray(\n",
        "            txt_values=[query],\n",
        "        ),\n",
        "    )],\n",
        "    result_granularity=visionai_v1.SearchResultGranularity.SEARCH_RESULT_GRANULARITY_PARTITION_LEVEL,\n",
        "    index_endpoint=index_endpoint_name,\n",
        "    result_annotation_keys=[\"title\"], # This helps returnning the response to include title annotation.\n",
        ")\n",
        "\n",
        "response = warehouse_client.search_index_endpoint(request=request)\n",
        "print(f\"Search: {response}\")"
      ],
      "metadata": {
        "id": "Ul38whlul_Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RenderResults(warehouse_client, response, top_k=5)"
      ],
      "metadata": {
        "id": "o0cHhlpBrRQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Search that matches the speech transcription results"
      ],
      "metadata": {
        "id": "u48HeE595vkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"oh my god\" # @param {type:\"string\"}\n",
        "data_schema_key=\"mgm-video-speech-transcription-001.transcript\" # @param {type: \"string\"}\n",
        "\n",
        "request=visionai_v1.SearchIndexEndpointRequest(\n",
        "    text_query=query,\n",
        "    criteria=[visionai_v1.Criteria(\n",
        "        field=data_schema_key,\n",
        "        text_array=visionai_v1.StringArray(\n",
        "            txt_values=[query],\n",
        "        ),\n",
        "    )],\n",
        "    result_granularity=visionai_v1.SearchResultGranularity.SEARCH_RESULT_GRANULARITY_PARTITION_LEVEL,\n",
        "    index_endpoint=index_endpoint_name,\n",
        "    result_annotation_keys=[\"title\"], # This helps returnning the response to include title annotation.\n",
        ")\n",
        "\n",
        "response = warehouse_client.search_index_endpoint(request=request)\n",
        "print(f\"Search: {response}\")"
      ],
      "metadata": {
        "id": "VkVfRULt5vkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RenderResults(warehouse_client, response, top_k=5)"
      ],
      "metadata": {
        "id": "bZp99tYD5vkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Clean Up"
      ],
      "metadata": {
        "id": "L2X3e4CH7olA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predefined Utils for cleaning up"
      ],
      "metadata": {
        "id": "M-7ycof8-Gv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_assets_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    parent_corpus_name: str,\n",
        ") -> Optional[visionai_v1.ListAssetsResponse]:\n",
        "    \"\"\"\n",
        "    List Assets within a corpus.\n",
        "    This is a non-LRO, synchronous call.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        parent_corpus_name: The resource name of the corpus to create the asset in.\n",
        "\n",
        "    Returns:\n",
        "        The resource name of assets under the corpus, or None if creation failed.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(f\"Listing assets in corpus '{parent_corpus_name}'...\")\n",
        "\n",
        "        request = visionai_v1.ListAssetsRequest(\n",
        "            parent=parent_corpus_name,\n",
        "            page_size=10,\n",
        "        )\n",
        "\n",
        "        response = client.list_assets(request=request)\n",
        "\n",
        "        return response\n",
        "\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while listing assets: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "def delete_asset_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    asset_name: str\n",
        ")-> Optional[bool]:\n",
        "    \"\"\"\n",
        "    Deletes an asset.\n",
        "    This is a non-LRO, synchronous call.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        asset_name: The resource name of the asset to delete.\n",
        "\n",
        "    Returns:\n",
        "        True if deletion was successful, False otherwise. None if an error occurred.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      logging.info(f\"Deleting assets in corpus '{asset_name}'...\")\n",
        "      request = visionai_v1.DeleteAssetRequest(\n",
        "            name=asset_name,\n",
        "      )\n",
        "\n",
        "      operation = client.delete_asset(request=request)\n",
        "      # TODO: Uncomment below after DeleteAsset populates response in LRO.\n",
        "      # response = operation.result()\n",
        "      return True\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while deleting asset: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "def undeploy_index_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    index_endpoint_name: str,\n",
        "    timeout_seconds: int = 7200\n",
        ") -> Optional[bool]:\n",
        "    \"\"\"\n",
        "    Undeploy index.\n",
        "    This is a LRO, asynchronous call.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        index_endpoint_name: The resource name of the index endpoint to undeploy.\n",
        "\n",
        "    Returns:\n",
        "        True if undeploy was successful, False otherwise. None if an error occurred.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      logging.info(f\"Undeploy index for index endpoint '{index_endpoint_name}'...\")\n",
        "      request = visionai_v1.UndeployIndexRequest(\n",
        "            index_endpoint=index_endpoint_name,\n",
        "      )\n",
        "\n",
        "      operation = client.undeploy_index(request=request)\n",
        "      logging.info(f\"Operation submitted. Operation name: {operation._operation.name}\")\n",
        "      logging.info(f\"â³Waiting for operation to complete (timeout: {timeout_seconds}s)...\")\n",
        "      response: visionai_v1.UndeployIndexResponse = operation.result(timeout=timeout_seconds)\n",
        "      return True\n",
        "    except TimeoutError:\n",
        "        logging.error(f\"Operation timed out after {timeout_seconds} seconds. \"\n",
        "                      \"The undeployment is ongoing in the background.\")\n",
        "        return None\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while undeploy index: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "\n",
        "def delete_index_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    index_name: str\n",
        ") -> Optional[bool]:\n",
        "    \"\"\"\n",
        "    Delete index.\n",
        "    This is a LRO, asynchronous call.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        index_name: The resource name of the index to delete.\n",
        "\n",
        "    Returns:\n",
        "        True if deletion was successful, False otherwise. None if an error occurred.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      logging.info(f\"Delete index for index endpoint '{index_name}'...\")\n",
        "      request = visionai_v1.DeleteIndexRequest(\n",
        "            name=index_name,\n",
        "      )\n",
        "\n",
        "      operation = client.delete_index(request=request)\n",
        "      # TODO: Uncomment below after DeleteIndex populates response in LRO.\n",
        "      # response = operation.result()\n",
        "      return True\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while deleting index: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "\n",
        "def delete_index_endpoint_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    index_endpoint_name: str\n",
        ") -> Optional[bool]:\n",
        "    \"\"\"\n",
        "    Delete index endpoint.\n",
        "    This is a LRO, asynchronous call.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        index_name: The resource name of the index endpoint to delete.\n",
        "\n",
        "    Returns:\n",
        "        True if deletion was successful, False otherwise. None if an error occurred.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      logging.info(f\"Delete index for index endpoint '{index_endpoint_name}'...\")\n",
        "      request = visionai_v1.DeleteIndexEndpointRequest(\n",
        "            name=index_endpoint_name,\n",
        "      )\n",
        "\n",
        "      operation = client.delete_index_endpoint(request=request)\n",
        "      # TODO: Uncomment below after DeleteIndexEndpoint populates response in LRO.\n",
        "      # response = operation.result()\n",
        "      return True\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while deleting index endpoint: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "\n",
        "def delete_corpus_robust(\n",
        "    client: visionai_v1.WarehouseClient,\n",
        "    corpus_name: str\n",
        ")-> Optional[bool]:\n",
        "    \"\"\"\n",
        "    Deletes a corpus.\n",
        "    This is a non-LRO, synchronous call.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        corpus_name: The resource name of the corpus to delete.\n",
        "\n",
        "    Returns:\n",
        "        True if deletion was successful, False otherwise. None if an error occurred.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      logging.info(f\"Deleting corpus '{corpus_name}'...\")\n",
        "      request = visionai_v1.DeleteCorpusRequest(\n",
        "            name=corpus_name,\n",
        "      )\n",
        "\n",
        "      response = client.delete_corpus(request=request)\n",
        "      return True\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while deleting asset: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return None"
      ],
      "metadata": {
        "id": "EdFgwJdk-MSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Delete Assets"
      ],
      "metadata": {
        "id": "dJIkE3ifNfOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if delete_assets_widget.value:\n",
        "    list_asset_response = list_assets_robust(warehouse_client, corpus_name)\n",
        "    for i, asset in enumerate(list_asset_response):\n",
        "      response = delete_asset_robust(warehouse_client, asset.name)\n",
        "      if not response:\n",
        "        logging.error(f\"âŒ Failed to delete asset: {asset.name}\")\n",
        "      else:\n",
        "        logging.info(f\"âœ… Deleted asset: {asset.name}\")"
      ],
      "metadata": {
        "id": "k5a6mSIsNl08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Undeploy Index"
      ],
      "metadata": {
        "id": "6neZMt-YSJh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if undeploy_index_widget.value:\n",
        "    response = undeploy_index_robust(warehouse_client, index_endpoint_name)\n",
        "    if not response:\n",
        "        logging.error(f\"âŒ Failed to undeploy index: {index_endpoint_name}\")\n",
        "    else:\n",
        "        logging.info(f\"âœ… Undeployed index: {index_endpoint_name}\")"
      ],
      "metadata": {
        "id": "Cpeva0y9Pavn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Delete Index"
      ],
      "metadata": {
        "id": "J_FxPqd3SQKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if delete_index_widget.value:\n",
        "    response = delete_index_robust(warehouse_client, index_name)\n",
        "    if not response:\n",
        "        logging.error(f\"âŒ Failed to delete index: {index_name}\")\n",
        "    else:\n",
        "        logging.info(f\"âœ… Deleted index: {index_name}\")"
      ],
      "metadata": {
        "id": "0_-5ni0WPjTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Delete Index Endpoint"
      ],
      "metadata": {
        "id": "K4zW3zFsSTgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if delete_index_endpoint_widget.value:\n",
        "    response = delete_index_endpoint_robust(warehouse_client, index_endpoint_name)\n",
        "    if not response:\n",
        "        logging.error(f\"âŒ Failed to delete index endpoint: {index_endpoint_name}\")\n",
        "    else:\n",
        "        logging.info(f\"âœ… Deleted index endpoint: {index_endpoint_name}\")"
      ],
      "metadata": {
        "id": "6jYTJ8H_PmXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Delete Corpus"
      ],
      "metadata": {
        "id": "ECRridUvSXtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if delete_corpus_widget.value:\n",
        "    response = delete_corpus_robust(warehouse_client, corpus_name)\n",
        "    if not response:\n",
        "        logging.error(f\"âŒ Failed to delete corpus: {corpus_name}\")\n",
        "    else:\n",
        "        logging.info(f\"âœ… Deleted corpus: {corpus_name}\")\n"
      ],
      "metadata": {
        "id": "j7C8AmZ67_Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wkUcSX6iv0z"
      },
      "source": [
        "# Part 2: More APIs Examples\n",
        "\n",
        "This section provides additional APIs for you to interact the Vision Warehouse resources.\n",
        "\n",
        "To see what we currently provide public: https://docs.cloud.google.com/vision-ai/docs/reference/rest\n",
        "\n",
        "To run sections below, you need to run sections \"Set Up Enviornment\", \"Download SDK\", \"Set Up Variables -> Set Your Project Id\", \"Provision New Or Use Existing Corpus/Index/IndexEndpoint\", \"Preparation\"."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More on Provision\n",
        "\n",
        "Examples of running CreateCorpus, CreateIndexEndpoint, CreateIndex, DeployIndex separately."
      ],
      "metadata": {
        "id": "kxqDFvr9KrsF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptoTJ86qDQ5Q"
      },
      "outputs": [],
      "source": [
        "# @title CreateCorpus\n",
        "\n",
        "# --- Default Search Capabilities (for easy reuse) ---\n",
        "DEFAULT_SEARCH_CAPABILITY = visionai_v1.SearchCapability(\n",
        "    type_=visionai_v1.SearchCapability.Type.DEFAULT_SEARCH,\n",
        ")\n",
        "SPEECH_SEARCH_CAPABILITY = visionai_v1.SearchCapability(\n",
        "    type_=visionai_v1.SearchCapability.Type.MODEL_GARDEN_MODEL_POWERED_SEARCH,\n",
        "    model_garden_model_powered_search_config=visionai_v1.SearchCapability.ModelGardenModelPoweredSearchConfig(\n",
        "        model_resource_id=\"video-speech-transcription@001\"\n",
        "    )\n",
        ")\n",
        "TEXT_SEARCH_CAPABILITY = visionai_v1.SearchCapability(\n",
        "    type_=visionai_v1.SearchCapability.Type.MODEL_GARDEN_MODEL_POWERED_SEARCH,\n",
        "    model_garden_model_powered_search_config=visionai_v1.SearchCapability.ModelGardenModelPoweredSearchConfig(\n",
        "        model_resource_id=\"video-text-detection@001\"\n",
        "    )\n",
        ")\n",
        "DEFAULT_VIDEO_ON_DEMAND_CAPABILITIES = [\n",
        "    DEFAULT_SEARCH_CAPABILITY,\n",
        "    SPEECH_SEARCH_CAPABILITY,\n",
        "    TEXT_SEARCH_CAPABILITY\n",
        "]\n",
        "\n",
        "param_corpus_display_name = \"python colab test corpus\" # @param {type: \"string\"}\n",
        "param_corpus_description = \"python colab test corpus\" # @param {type: \"string\"}\n",
        "\n",
        "\n",
        "if 'warehouse_client' in locals() and 'PROJECT_NUMBER' in locals() and 'LOCATION_ID' in locals():\n",
        "    logging.info(\"--- Starting New Corpus Creation ---\")\n",
        "    new_corpus_name = create_corpus_robust(\n",
        "        client=warehouse_client,\n",
        "        project_number=PROJECT_NUMBER,\n",
        "        location_id=LOCATION_ID,\n",
        "        display_name=param_corpus_display_name,\n",
        "        description=param_corpus_description,\n",
        "        search_capabilities=DEFAULT_VIDEO_ON_DEMAND_CAPABILITIES,\n",
        "    )\n",
        "\n",
        "    if new_corpus_name:\n",
        "        print(f\"\\nâœ… Corpus created successfully: {new_corpus_name}\")\n",
        "        # You would then assign this to the global `corpus_name`\n",
        "        corpus_name = new_corpus_name\n",
        "    else:\n",
        "        print(f\"\\nâŒ Corpus creation failed. Check logs above for errors.\")\n",
        "else:\n",
        "    logging.error(\"`warehouse_client`, `PROJECT_NUMBER`, or `LOCATION_ID` is not defined. \"\n",
        "                  \"Please run the initialization cells.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "FDs_qd58EhK9"
      },
      "outputs": [],
      "source": [
        "# @title CreateIndex\n",
        "# Appriximately takes 30min - 60min\n",
        "\n",
        "param_display_name = \"python colab test\" # @param {type: \"string\"}\n",
        "param_description = \"python colab test\" # @param {type: \"string\"}\n",
        "\n",
        "if 'warehouse_client' in locals() and 'corpus_name' in locals():\n",
        "    logging.info(\"--- Starting New Index Creation ---\")\n",
        "    new_index_name = create_index_robust(\n",
        "        client=warehouse_client,\n",
        "        parent_corpus_name=corpus_name,\n",
        "        display_name=param_display_name,\n",
        "        description=param_description,\n",
        "        timeout_seconds=7200  # You can adjust this\n",
        "    )\n",
        "\n",
        "    if new_index_name:\n",
        "        print(f\"\\nâœ… Index created successfully: {new_index_name}\")\n",
        "        # You would then assign this to the global `index_name`\n",
        "        index_name = new_index_name\n",
        "    else:\n",
        "        print(f\"\\nâŒ Index creation failed. Check logs above for errors.\")\n",
        "else:\n",
        "    logging.error(\"`warehouse_client` or `corpus_name` is not defined. \"\n",
        "                  \"Please run the initialization cells.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTEgC4JdVOQj"
      },
      "outputs": [],
      "source": [
        "# @title CreateEndpoint\n",
        "# Appriximately takes 30min - 60min\n",
        "\n",
        "# --- Colab Parameters ---\n",
        "param_display_name = \"python colab test\" # @param {type: \"string\"}\n",
        "param_description = \"python colab test\" # @param {type: \"string\"\n",
        "\n",
        "\n",
        "if 'warehouse_client' in locals() and 'PROJECT_NUMBER' in locals() and 'LOCATION_ID' in locals():\n",
        "    logging.info(\"--- Starting New IndexEndpoint Creation ---\")\n",
        "    new_index_endpoint_name = create_index_endpoint_robust(\n",
        "        client=warehouse_client,\n",
        "        project_number=PROJECT_NUMBER,\n",
        "        location_id=LOCATION_ID,\n",
        "        display_name=param_display_name,\n",
        "        description=param_description,\n",
        "        timeout_seconds=3600  # You can adjust this\n",
        "    )\n",
        "\n",
        "    if new_index_endpoint_name:\n",
        "        print(f\"\\nâœ… IndexEndpoint created successfully: {new_index_endpoint_name}\")\n",
        "        # You would then assign this to the global `index_name`\n",
        "        index_endpoint_name = new_index_endpoint_name\n",
        "    else:\n",
        "        print(f\"\\nâŒ IndexEndpoint creation failed. Check logs above for errors.\")\n",
        "else:\n",
        "    logging.error(\"`warehouse_client`, `PROJECT_NUMBER`, or `LOCATION_ID` is not defined. \"\n",
        "                  \"Please run the initialization cells.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjNU3y2nYxCE"
      },
      "outputs": [],
      "source": [
        "# @title DeployIndexEndpoint\n",
        "# Appriximately takes 30min - 60min\n",
        "\n",
        "if 'warehouse_client' in locals() and 'index_name' in locals() and 'index_endpoint_name' in locals():\n",
        "    logging.info(\"--- Starting New IndexEndpoint Creation ---\")\n",
        "    resp = deploy_index_endpoint_robust(\n",
        "        client=warehouse_client,\n",
        "        index_endpoint_name=index_endpoint_name,\n",
        "        index_name=index_name,\n",
        "        timeout_seconds=7200  # You can adjust this\n",
        "    )\n",
        "\n",
        "    if resp:\n",
        "        print(f\"\\nâœ… IndexEndpoint deployed successfully: {new_index_name}\")\n",
        "    else:\n",
        "        print(f\"\\nâŒ IndexEndpoint deployment failed. Check logs above for errors.\")\n",
        "else:\n",
        "    logging.error(\"`warehouse_client`, `index_name`, or `index_endpoint_name` is not defined. \"\n",
        "                  \"Please run the initialization cells.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgXLs4Z5Xd0d"
      },
      "outputs": [],
      "source": [
        "# @title Example for fetching operation manually\n",
        "# You only need to run this if previous step is interrupted.\n",
        "\n",
        "operation_name =\"\" # @param {type: \"string\"}\n",
        "\n",
        "\n",
        "def check_operation_status(\n",
        "    client: WarehouseClient,\n",
        "    operation_name: str\n",
        ") -> Optional[operations_pb2.Operation]:\n",
        "    \"\"\"\n",
        "    Manually fetches the status of a long-running operation given its name.\n",
        "\n",
        "    Args:\n",
        "        client: The initialized WarehouseClient.\n",
        "        operation_name: The full name of the operation\n",
        "                        (e.g., \"projects/.../locations/.../operations/...\").\n",
        "\n",
        "    Returns:\n",
        "        The operation object itself, or None if an error occurred.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(f\"Fetching status for operation: {operation_name}\")\n",
        "\n",
        "        # Make the request to get the operation\n",
        "        request = operations_pb2.GetOperationRequest(name=operation_name)\n",
        "        operation = client.get_operation(request=request)\n",
        "\n",
        "        if operation.done:\n",
        "            logging.info(\"Operation is complete.\")\n",
        "            if operation.error.message:\n",
        "                logging.error(f\"Operation failed with error: {operation.error.message}\")\n",
        "            else:\n",
        "                logging.info(\"Operation completed successfully.\")\n",
        "                logging.debug(f\"Operation response: {operation.response}\")\n",
        "        else:\n",
        "            logging.info(\"Operation is still running.\")\n",
        "            logging.debug(f\"Operation metadata: {operation.metadata}\")\n",
        "\n",
        "        return operation\n",
        "\n",
        "    except google_exceptions.GoogleAPICallError as e:\n",
        "        logging.error(f\"API error while checking operation '{operation_name}': {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "\n",
        "# # Paste the operation name you got from the logs\n",
        "\n",
        "if 'warehouse_client' in locals():\n",
        "    logging.info(\"--- Checking Operation Status ---\")\n",
        "    op_status = check_operation_status(\n",
        "        client=warehouse_client,\n",
        "        operation_name=operation_name\n",
        "    )\n",
        "\n",
        "    if op_status:\n",
        "        print(f\"\\nâœ… Status check complete. Done: {op_status.done}\")\n",
        "    else:\n",
        "        print(f\"\\nâŒ Failed to check operation status. See logs.\")\n",
        "else:\n",
        "    logging.error(\"`warehouse_client` is not defined. \"\n",
        "                  \"Please run the initialization cells.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdHoZOTBfWjN"
      },
      "source": [
        "## More on Corpus\n",
        "\n",
        "You can list/get Corpus/Index/IndexEndpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_nUWwZvRfh5e"
      },
      "outputs": [],
      "source": [
        "# @title ListCorpora\n",
        "parent_name = f\"projects/{PROJECT_NUMBER}/locations/us-central1\"\n",
        "request = visionai_v1.ListCorporaRequest(\n",
        "        parent=parent_name,\n",
        "    )\n",
        "\n",
        "response = warehouse_client.list_corpora(request=request)\n",
        "print(f\"Corpus List: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "F9krYbOZgxbu"
      },
      "outputs": [],
      "source": [
        "# @title GetCorpus\n",
        "corpus_id = \"\" # @param {type: \"string\"}\n",
        "corpus_name = f\"projects/{PROJECT_NUMBER}/locations/us-central1/corpora/{corpus_id}\"\n",
        "request = visionai_v1.GetCorpusRequest(\n",
        "    name=corpus_name,\n",
        ")\n",
        "response = warehouse_client.get_corpus(request=request)\n",
        "print(f\"Corpus: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XIkBjHQZlKvF"
      },
      "outputs": [],
      "source": [
        "# @title ListIndexes\n",
        "corpus_id=\"\" # @param {type: \"string\"}\n",
        "corpus_name = f\"projects/{PROJECT_NUMBER}/locations/us-central1/corpora/{corpus_id}\"\n",
        "request = visionai_v1.ListIndexesRequest(\n",
        "          parent=corpus_name,\n",
        "      )\n",
        "response = warehouse_client.list_indexes(request=request)\n",
        "print(f\"Index List: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zUrbJpdym8YO"
      },
      "outputs": [],
      "source": [
        "# @title GetIndex\n",
        "index_id=\"\" # @param {type: \"string\"}\n",
        "index_name=f\"{corpus_name}/indexes/{index_id}\"\n",
        "request = visionai_v1.GetIndexRequest(\n",
        "    name=index_name,\n",
        ")\n",
        "response = warehouse_client.get_index(request=request)\n",
        "print(f\"Index: {response}\")\n",
        "index_name=response.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jLqwxNm5iMWs"
      },
      "outputs": [],
      "source": [
        "# @title ListIndexEndpoint\n",
        "parent_name = f\"projects/{PROJECT_NUMBER}/locations/us-central1\"\n",
        "request = visionai_v1.ListIndexEndpointsRequest(\n",
        "          parent=parent_name,\n",
        "      )\n",
        "response = warehouse_client.list_index_endpoints(request=request)\n",
        "print(f\"IndexEndpoint List: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NieecgodijPK"
      },
      "outputs": [],
      "source": [
        "# @title GetIndexEndpoint\n",
        "index_endpoint_id=\"\" # @param {type: \"string\"}\n",
        "index_endpoint_name=f\"projects/{PROJECT_NUMBER}/locations/us-central1/indexEndpoints/{index_endpoint_id}\"\n",
        "request = visionai_v1.GetIndexEndpointRequest(\n",
        "    name=index_endpoint_name,\n",
        ")\n",
        "response = warehouse_client.get_index_endpoint(request=request)\n",
        "print(f\"IndexEndpoint: {response}\")\n",
        "index_endpoint_name=response.name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cam4eJPir0A_"
      },
      "source": [
        "## More on Assets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3wpkVvQryik"
      },
      "outputs": [],
      "source": [
        "# @title GetAsset\n",
        "asset_id=\"\"  # @param {type: \"string\"}\n",
        "asset_name=f\"projects/{PROJECT_NUMBER}/locations/us-central1/corpora/{corpus_id}/assets/{asset_id}\"\n",
        "request = visionai_v1.GetAssetRequest(\n",
        "    name=asset_name,\n",
        ")\n",
        "response = warehouse_client.get_asset(request=request)\n",
        "print(f\"Asset: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqIm2zTir3-X"
      },
      "outputs": [],
      "source": [
        "# @title IndexAsset\n",
        "asset_id=\"\"  # @param {type: \"string\"}\n",
        "asset_name=f\"projects/{PROJECT_NUMBER}/locations/us-central1/corpora/{corpus_id}/assets/{asset_id}\"\n",
        "index_id=\"\" # @param {type: \"string\"}\n",
        "index_name=f\"{corpus_name}/indexes/{index_id}\"\n",
        "request = visionai_v1.IndexAssetRequest(\n",
        "    name=asset_name,\n",
        "    index_asset_level_only=False, # Indexing segment signals or all\n",
        "    index=index_name\n",
        ")\n",
        "operation = warehouse_client.index_asset(request=request)\n",
        "response = operation.result()\n",
        "print(f\"IndexAsset: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgs8-oxp2NIm"
      },
      "source": [
        "## More on Metadata\n",
        "\n",
        "There are many features we provide on the metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9owy0Gg33NPx"
      },
      "outputs": [],
      "source": [
        "# @title ListAnnotations - ML metadata\n",
        "# You can filter by default two ML keys:\n",
        "# Text: mgm-video-text-detection-001\n",
        "# Speech: mgm-video-speech-transcription-001\n",
        "\n",
        "asset_id=\"\"  # @param {type: \"string\"}\n",
        "asset_name=f\"projects/{PROJECT_NUMBER}/locations/us-central1/corpora/{corpus_id}/assets/{asset_id}\"\n",
        "filter_key=\"mgm-video-text-detection-001\"\n",
        "\n",
        "request=visionai_v1.ListAnnotationsRequest(\n",
        "    parent=asset_name,\n",
        "    filter=f\"key={filter_key}\"\n",
        "\n",
        ")\n",
        "response = warehouse_client.list_annotations(request=request)\n",
        "print(f\"Annotations: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ALudFdY3CD5"
      },
      "outputs": [],
      "source": [
        "# @title ListAnnotations - Your own metadata\n",
        "# This is helpful specifically for segment metadata listing\n",
        "# For example, if you have segment level data schemas defined,\n",
        "# this API can help you list all segments value matches with this schema.\n",
        "\n",
        "asset_id=\"\"  # @param {type: \"string\"}\n",
        "asset_name=f\"projects/{PROJECT_NUMBER}/locations/us-central1/corpora/{corpus_id}/assets/{asset_id}\"\n",
        "filter_key=\"\" # @param {type: \"string\"}\n",
        "\n",
        "request=visionai_v1.ListAnnotationsRequest(\n",
        "    parent=asset_name,\n",
        "    filter=f\"key={filter_key}\"\n",
        "\n",
        ")\n",
        "response = warehouse_client.list_annotations(request=request)\n",
        "print(f\"Annotations: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_r_ZPlXGbfu"
      },
      "source": [
        "### Data Schemas - Other types\n",
        "\n",
        "Vision Warehouse supprots all types of schemas: https://docs.cloud.google.com/vision-ai/docs/reference/rest/v1alpha1/projects.locations.corpora.dataSchemas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzrY5dEXhAwt"
      },
      "outputs": [],
      "source": [
        "# @title Data Schemas - Date Range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cec3TlpW3Tm0"
      },
      "outputs": [],
      "source": [
        "# @title Data Schema - Complex struct\n",
        "# VisionWarehouse provides complex data schemas for your business needs."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqP8-O6vH9wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FPYTgIPuJz-"
      },
      "source": [
        "### Example: Metadata creation and index\n",
        "\n",
        "You can define more your own metadata on the assets.\n",
        "\n",
        "--------------------------------------\n",
        "\n",
        "\n",
        "| Step | Approximately time |\n",
        "| :--- | :--- |\n",
        "| CreateDataSchema API | Instance |\n",
        "| CreateAnnotation API | Instance |\n",
        "| IndexAsset API | a few minutes |\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define a schema at Asset Level"
      ],
      "metadata": {
        "id": "CVHKmv5vIUAK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhkpttLCz9PU"
      },
      "outputs": [],
      "source": [
        "\n",
        "your_data_schema_key=\"description\" # @param {type: \"string\"}\n",
        "\n",
        "data_schema=visionai_v1.DataSchema(\n",
        "    key=your_data_schema_key,\n",
        "    schema_details=visionai_v1.DataSchemaDetails(\n",
        "        type_=visionai_v1.DataSchemaDetails.DataType.STRING,\n",
        "        granularity=visionai_v1.DataSchemaDetails.Granularity.GRANULARITY_ASSET_LEVEL,\n",
        "        search_strategy=visionai_v1.DataSchemaDetails.SearchStrategy(\n",
        "            search_strategy_type=visionai_v1.DataSchemaDetails.SearchStrategy.SearchStrategyType.SMART_SEARCH\n",
        "        )\n",
        "    )\n",
        ")\n",
        "request = visionai_v1.CreateDataSchemaRequest(\n",
        "    parent=corpus_name,\n",
        "    data_schema=data_schema,\n",
        ")\n",
        "\n",
        "response = warehouse_client.create_data_schema(request=request)\n",
        "print(f\"DataSchema: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Create the corresponding metadata"
      ],
      "metadata": {
        "id": "WLnH-KTpIdAv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85uZTS9nWsAx"
      },
      "outputs": [],
      "source": [
        "asset_id = \"16995729758365416897\" # @param {type: \"string\"}\n",
        "asset_name=f\"projects/{PROJECT_NUMBER}/locations/us-central1/corpora/{corpus_id}/assets/{asset_id}\"\n",
        "annotation_value = \"a man is driving a car\" # @param {type: \"string\"}\n",
        "\n",
        "your_annotation = visionai_v1.Annotation(\n",
        "    user_specified_annotation=visionai_v1.UserSpecifiedAnnotation(\n",
        "        key=your_data_schema_key,\n",
        "        value=visionai_v1.AnnotationValue(\n",
        "            str_value=annotation_value\n",
        "        )\n",
        "    )\n",
        ")\n",
        "request = visionai_v1.CreateAnnotationRequest(\n",
        "    parent=asset_name,\n",
        "    annotation=your_annotation,\n",
        ")\n",
        "\n",
        "response = warehouse_client.create_annotation(request=request)\n",
        "print(f\"Annotation: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a schema at Segment Level"
      ],
      "metadata": {
        "id": "SymyNbiTIj92"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU04NuZOz_ju"
      },
      "outputs": [],
      "source": [
        "your_seg_data_schema_key=\"logs\" # @param {type: \"string\"}\n",
        "\n",
        "seg_data_schema=visionai_v1.DataSchema(\n",
        "    key=your_seg_data_schema_key,\n",
        "    schema_details=visionai_v1.DataSchemaDetails(\n",
        "        type_=visionai_v1.DataSchemaDetails.DataType.STRING,\n",
        "        granularity=visionai_v1.DataSchemaDetails.Granularity.GRANULARITY_PARTITION_LEVEL,\n",
        "        search_strategy=visionai_v1.DataSchemaDetails.SearchStrategy(\n",
        "            search_strategy_type=visionai_v1.DataSchemaDetails.SearchStrategy.SearchStrategyType.SMART_SEARCH\n",
        "        )\n",
        "    )\n",
        ")\n",
        "request = visionai_v1.CreateDataSchemaRequest(\n",
        "    parent=corpus_name,\n",
        "    data_schema=seg_data_schema,\n",
        ")\n",
        "\n",
        "response = warehouse_client.create_data_schema(request=request)\n",
        "print(f\"DataSchema: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create the corresponding metadata"
      ],
      "metadata": {
        "id": "EDUq9NzbIpKB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAXfnF4qWvki"
      },
      "outputs": [],
      "source": [
        "asset_id = \"16995729758365416897\" # @param {type: \"string\"}\n",
        "asset_name=f\"projects/{PROJECT_NUMBER}/locations/us-central1/corpora/{corpus_id}/assets/{asset_id}\"\n",
        "your_seg_data_schema_key=\"logs\" # @param {type: \"string\"}\n",
        "seg_annotation_value = \"singing and smile\" # @param {type: \"string\"}\n",
        "start_seconds=5 # @param {type: \"number\"}\n",
        "end_seconds=10 # @param {type: \"number\"}\n",
        "\n",
        "your_seg_annotation = visionai_v1.Annotation(\n",
        "    user_specified_annotation=visionai_v1.UserSpecifiedAnnotation(\n",
        "        key=your_seg_data_schema_key,\n",
        "        value=visionai_v1.AnnotationValue(\n",
        "            str_value=seg_annotation_value\n",
        "        ),\n",
        "        partition=visionai_v1.Partition(\n",
        "            relative_temporal_partition=visionai_v1.Partition.RelativeTemporalPartition(\n",
        "              start_offset=duration_pb2.Duration(\n",
        "                  seconds=start_seconds,\n",
        "              ),\n",
        "              end_offset=duration_pb2.Duration(\n",
        "                  seconds=end_seconds,\n",
        "              )\n",
        "            )\n",
        "        )\n",
        "    )\n",
        ")\n",
        "request = visionai_v1.CreateAnnotationRequest(\n",
        "    parent=asset_name,\n",
        "    annotation=your_seg_annotation,\n",
        ")\n",
        "\n",
        "response = warehouse_client.create_annotation(request=request)\n",
        "print(f\"Annotation: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run Indexing"
      ],
      "metadata": {
        "id": "SAyQcThkIscL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0S2FarZ0EO5"
      },
      "outputs": [],
      "source": [
        "asset_id=\"16995729758365416897\"  # @param {type: \"string\"}\n",
        "asset_name=f\"projects/{PROJECT_NUMBER}/locations/us-central1/corpora/{corpus_id}/assets/{asset_id}\"\n",
        "index_id=\"index-5657433150604653294\" # @param {type: \"string\"}\n",
        "index_name=f\"{corpus_name}/indexes/{index_id}\"\n",
        "request = visionai_v1.IndexAssetRequest(\n",
        "    name=asset_name,\n",
        "    index_asset_level_only=False, # Indexing segment signals or all\n",
        "    index=index_name\n",
        ")\n",
        "operation = warehouse_client.index_asset(request=request)\n",
        "response = operation.result()\n",
        "print(f\"IndexAsset: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "volkENKpjtJa"
      },
      "source": [
        "## More on Search\n",
        "\n",
        "Customer can create facets and hypernyms for their customized search experience."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GllblerH9U_u"
      },
      "source": [
        "### Facet Search\n",
        "\n",
        "To enable facet search, you should create a bunch of facets, they should be aligned with the data schemas you created.\n",
        "\n",
        "\n",
        "You can see more details in the public documentation: https://docs.cloud.google.com/vision-ai/docs/reference/rest/v1alpha1/projects.locations.corpora.searchConfigs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnpyE2KCjya6"
      },
      "outputs": [],
      "source": [
        "# @title Create Data Schema\n",
        "your_data_schema_key=\"teams\" # @param {type: \"string\"}\n",
        "\n",
        "# The facets need to map to the data schemas you created.\n",
        "# For example, if you create a data schema calls \"Content-Type\"\n",
        "data_schema=visionai_v1.DataSchema(\n",
        "    key=your_data_schema_key,\n",
        "    schema_details=visionai_v1.DataSchemaDetails(\n",
        "        type_=visionai_v1.DataSchemaDetails.DataType.STRING,\n",
        "        granularity=visionai_v1.DataSchemaDetails.Granularity.GRANULARITY_ASSET_LEVEL,\n",
        "        search_strategy=visionai_v1.DataSchemaDetails.SearchStrategy(\n",
        "            search_strategy_type=visionai_v1.DataSchemaDetails.SearchStrategy.SearchStrategyType.SMART_SEARCH\n",
        "        )\n",
        "    )\n",
        ")\n",
        "request = visionai_v1.CreateDataSchemaRequest(\n",
        "    parent=corpus_name,\n",
        "    data_schema=data_schema,\n",
        ")\n",
        "\n",
        "response = warehouse_client.create_data_schema(request=request)\n",
        "print(f\"DataSchema: {response}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JZvT8Qt4pBeV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# @title Create Annotations\n",
        "# Then you create corresponding annotations\n",
        "\n",
        "asset_id = \"\" # @param {type: \"string\"}\n",
        "asset_name=f\"projects/{PROJECT_NUMBER}/locations/us-central1/corpora/{corpus_id}/assets/{asset_id}\"\n",
        "annotation_value = \"Golden\" # @param {type: \"string\"}\n",
        "\n",
        "your_annotation = visionai_v1.Annotation(\n",
        "    user_specified_annotation=visionai_v1.UserSpecifiedAnnotation(\n",
        "        key=your_data_schema_key,\n",
        "        value=visionai_v1.AnnotationValue(\n",
        "            str_value=annotation_value\n",
        "        )\n",
        "    )\n",
        ")\n",
        "request = visionai_v1.CreateAnnotationRequest(\n",
        "    parent=asset_name,\n",
        "    annotation=your_annotation,\n",
        ")\n",
        "response = warehouse_client.create_annotation(request=request)\n",
        "print(f\"Annotation: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPm7Zz4cB4z1"
      },
      "outputs": [],
      "source": [
        "# @title IndexAsset\n",
        "asset_id=\"\"  # @param {type: \"string\"}\n",
        "asset_name=f\"projects/{PROJECT_NUMBER}/locations/us-central1/corpora/{corpus_id}/assets/{asset_id}\"\n",
        "index_id=\"\" # @param {type: \"string\"}\n",
        "index_name=f\"{corpus_name}/indexes/{index_id}\"\n",
        "request = visionai_v1.IndexAssetRequest(\n",
        "    name=asset_name,\n",
        "    index_asset_level_only=False, # Indexing segment signals or all\n",
        "    index=index_name\n",
        ")\n",
        "operation = warehouse_client.index_asset(request=request)\n",
        "response = operation.result()\n",
        "print(f\"IndexAsset: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETEzaXg1ozrJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# @title Create Facets - 1 dimesion\n",
        "# 1 dimension facet means 1 data schema key maps to 1 facet.\n",
        "\n",
        "corpus_id=\"\" # @param {type: \"string\"}\n",
        "corpus_name = f\"projects/{PROJECT_NUMBER}/locations/us-central1/corpora/{corpus_id}\"\n",
        "request=visionai_v1.CreateSearchConfigRequest(\n",
        "    parent=corpus_name,\n",
        "    search_config_id=\"teams\",\n",
        "    search_config=visionai_v1.SearchConfig(\n",
        "        facet_property=visionai_v1.FacetProperty(\n",
        "            mapped_fields=[\"teams\"],\n",
        "            display_name=\"teams\",\n",
        "            result_size=2,\n",
        "            bucket_type=visionai_v1.FacetBucketType.FACET_BUCKET_TYPE_VALUE,\n",
        "        )\n",
        "    )\n",
        ")\n",
        "response = warehouse_client.create_search_config(request=request)\n",
        "print(f\"SearchConfig: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EJysQy7TAQqL"
      },
      "outputs": [],
      "source": [
        "# @title Search with facet selected\n",
        "query=\"video0\" # @param {type:\"string\"}\n",
        "\n",
        "request=visionai_v1.SearchIndexEndpointRequest(\n",
        "    text_query=query,\n",
        "    result_granularity=visionai_v1.SearchResultGranularity.SEARCH_RESULT_GRANULARITY_ASSET_LEVEL,\n",
        "    index_endpoint=index_endpoint_name,\n",
        "    result_annotation_keys=[\"title\", \"teams\"],\n",
        "    facet_selections=[visionai_v1.FacetGroup(\n",
        "        facet_id=\"teams\",\n",
        "        buckets=[visionai_v1.FacetBucket(\n",
        "            value=visionai_v1.FacetValue(\n",
        "                string_value=\"Golden\"\n",
        "            ),\n",
        "            selected=True,\n",
        "        )],\n",
        "        bucket_type=visionai_v1.FacetBucketType.FACET_BUCKET_TYPE_VALUE,\n",
        "    )]\n",
        ")\n",
        "\n",
        "response = warehouse_client.search_index_endpoint(request=request)\n",
        "print(f\"Search: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aITWcpLp_6CO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# @title Create Facets - n dimesion\n",
        "# 1 dimension facet means n data schema key maps to 1 facet.\n",
        "# For example, you can have data schema as home_team, away_team, and map to teams.\n",
        "\n",
        "corpus_id=\"\" # @param {type: \"string\"}\n",
        "corpus_name = f\"projects/{PROJECT_NUMBER}/locations/us-central1/corpora/{corpus_id}\"\n",
        "request=visionai_v1.CreateSearchConfigRequest(\n",
        "    parent=corpus_name,\n",
        "    search_config_id=\"teams\", # make sure you update the id.\n",
        "    search_config=visionai_v1.SearchConfig(\n",
        "        facet_property=visionai_v1.FacetProperty(\n",
        "            mapped_fields=[\"home_team\", \"away_team\"], # make sure you precreate them.\n",
        "            display_name=\"teams\",\n",
        "            result_size=2,\n",
        "            bucket_type=visionai_v1.FacetBucketType.FACET_BUCKET_TYPE_VALUE,\n",
        "        )\n",
        "    )\n",
        ")\n",
        "response = warehouse_client.create_search_config(request=request)\n",
        "print(f\"SearchConfig: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5r-OxoXDMZ4"
      },
      "source": [
        "### Hypernyms Search\n",
        "\n",
        "You can create similar words to help search. For example, some abbreviation to map to the full name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQfX7o3Oj0iJ"
      },
      "outputs": [],
      "source": [
        "# @title Create hypernyms\n",
        "\n",
        "# The idea is that later you can search the hypernym in the query,\n",
        "# instead of hypernym_1, hypernyms_2 which are actually metadata.\n",
        "# For example, there is annotation value as \"a man is dring car\",\n",
        "# After I create a hypernyms \"spaceship\" mapping to \"car\",\n",
        "# Next time when I search \"spaceship\", it will return the annotation which\n",
        "# include \"car\".\n",
        "\n",
        "hypernym=\"spaceship\" # @param {type:\"string\"}\n",
        "hypernym_1=\"truck\" # @param {type:\"string\"}\n",
        "hypernym_2=\"car\" # @param {type:\"string\"}\n",
        "\n",
        "corpus_id=\"\" # @param {type: \"string\"}\n",
        "corpus_name = f\"projects/{PROJECT_NUMBER}/locations/us-central1/corpora/{corpus_id}\"\n",
        "request=visionai_v1.CreateSearchHypernymRequest(\n",
        "    parent=corpus_name,\n",
        "    search_hypernym=visionai_v1.SearchHypernym(\n",
        "        hypernym=hypernym,\n",
        "        hyponyms=[hypernym_1, hypernym_2]\n",
        "    )\n",
        ")\n",
        "response = warehouse_client.create_search_hypernym(request=request)\n",
        "print(f\"SearchHypernyms: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ui-hMCXUjHTF"
      },
      "outputs": [],
      "source": [
        "# @title Search with hypernyms\n",
        "query=\"spaceship\" # @param {type:\"string\"}\n",
        "\n",
        "request=visionai_v1.SearchIndexEndpointRequest(\n",
        "    text_query=query,\n",
        "    result_granularity=visionai_v1.SearchResultGranularity.SEARCH_RESULT_GRANULARITY_PARTITION_LEVEL,\n",
        "    index_endpoint=index_endpoint_name,\n",
        "    result_annotation_keys=[\"title\"],\n",
        ")\n",
        "\n",
        "response = warehouse_client.search_index_endpoint(request=request)\n",
        "print(f\"Search: {response}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "collapsed_sections": [
        "WL_aTssbVQuE",
        "_u3VBgth5zGW",
        "ihq_z_yrTvhJ",
        "Y5X5vuwzUymI",
        "XxLS0XVaBZXi",
        "EFaXutXqwPwJ",
        "KXr3lD8MwVcN",
        "TnAfLUIjwkUY",
        "nnA-HxtH5fNS",
        "u48HeE595vkq",
        "SAyQcThkIscL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}